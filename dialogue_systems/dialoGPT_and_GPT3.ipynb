{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "sWSKj0vMCN9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "CNZXTDxTjjdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d28fe8c-d431-42fc-93bd-78701df97561"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 27.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 13.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import GPT2Config, AdamW\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "print(tokenizer.bos_token, tokenizer.eos_token, tokenizer.pad_token, tokenizer.sep_token)"
      ],
      "metadata": {
        "id": "EiqS1m7MjkY3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198,
          "referenced_widgets": [
            "f55aef7338844e0b8a9198c33446a954",
            "b304697996924481945e7073e0a7acee",
            "9b8a3f3e49a34c008bf20b3248722b88",
            "cafe54fc10d54efb8b3a124958d451a6",
            "301e6b3a82ed44dbaab01a5a3e5750ea",
            "8e9e78c4b8be4cf49fbd97a9a537d3fe",
            "d047ac7776114e20885abeb63a842ff2",
            "5156ce5b76a8470989ea031c629647c0",
            "165f2427d60148afb703c62b2ec6e1c1",
            "166c256b0b3a4311b494c6b41941988e",
            "719c241005e54fc0954dee70a71c37b5",
            "284889869960411abd2ce5c98f9d6954",
            "2a0b096a112d452094e6b5f2aeb84fda",
            "71238fb1bdd8407ab29f808ceedf509e",
            "8094436f82d548e4bc751eaa9f3551b0",
            "6c15e40b86af4794a734aaac2ac2bbcc",
            "ff9dce8e552944039a9a7e8d999e440b",
            "09c3a165496b4e25811066fd077806d9",
            "bd3809acf8b04af7a97b004d6a8046ed",
            "4aaea2039bfb47bd9572a3b852100359",
            "b4873c50b5b94e02ba8fac27a5ff7bf9",
            "b2371d20d6df4dcdbbb500e150421c10",
            "aa13abaca4d2451bbbea5b1454678978",
            "3ca84db8b28f4fe086885ae051be64d2",
            "de71115341884b8c9cb3e85ca2a0e101",
            "c681b174355e4424bc4b51ca862ad7b5",
            "8e5e4a03836b490cbe416d91e6b71e32",
            "fbf70e5022e140b58799ee024b061136",
            "74fc84e951fa4ca79334f5b2ae79c85f",
            "3f618254564c4370b316b1f749055e7b",
            "c3cfffff1ed14e15a853c21954fe0dac",
            "583441d5388348428f6ec0145609145d",
            "c4c1a50eb32c4967acaf5e87dd3c64f3",
            "1d0eb374b1cf42e3a1806284f426cf8a",
            "68e1c2b77c0d463cb3c789c05327254a",
            "59c041e8d52242e9b4c8e7c17a94dd5e",
            "09a9a0f01ad546ebb52526288ee213d6",
            "3eb04ea405014f6d9aabfcfa87faad4d",
            "6c4a7b88bd074875a0f7c0b5a53605cd",
            "1cc04b2326d44803b90c7e6145210fc8",
            "1680942f0edb4971b4508303e8a287d1",
            "b7eef218d03e41018b00cfa949845926",
            "3313fda598724e619fae3d5aa3ae6809",
            "5e7eb0212e094899bfd7b3834c9660d5"
          ]
        },
        "outputId": "fc6d11c9-d88f-4e28-f5d5-866b3e14cb99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f55aef7338844e0b8a9198c33446a954"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "284889869960411abd2ce5c98f9d6954"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa13abaca4d2451bbbea5b1454678978"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d0eb374b1cf42e3a1806284f426cf8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using pad_token, but it is not set yet.\n",
            "Using sep_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|> <|endoftext|> None None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "from transformers import AutoModelForCausalLM\n",
        "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=\"microsoft/DialoGPT-medium\").to(device)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "bde4ee31d0ff488fbaa09f308ecf4ee7",
            "81c943ebe1624844a8a890a31346436e",
            "19ad44921e72414cb65040288fd0c60e",
            "f3e021fa17584d3ea27ae1a707476317",
            "0cf6d8f0c4b24b5da5d61c48cfd562a5",
            "7306138d8fac4b4599100e87bc8bb0ac",
            "56c10acda9de4b40af8fb2028f5412de",
            "97c6de4671af4f169cd923ebaebce4bc",
            "c802f79846c541d8b6f1e3a3e0fd6459",
            "ff8a620c35ed4f9d9820dad6e3dae69e",
            "57fcbbff8b654052b37fa859b436e4ae"
          ]
        },
        "id": "3oyig-EQCMCf",
        "outputId": "7313dba4-34ec-4f8a-f05d-1964efdd70a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/823M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bde4ee31d0ff488fbaa09f308ecf4ee7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune DalioGPT on LIGHT"
      ],
      "metadata": {
        "id": "JPQWwcrgCDs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Light environment\n",
        "\n",
        "The LIGHT data was released as part of the Facebook's ParlAI system.\n",
        "\n",
        "> The original LIGHT dataset features 663 locations, 3462 objects and 1755 character types, described entirely in natural language. Within that game world, we collected 11,000 episodes of character interactions (talking and acting).\n",
        "\n",
        "We can access it using `parlai display_data -t light_dialog`. "
      ],
      "metadata": {
        "id": "6NX6b27Si2WX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IGKKGBqBqEmu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "json_filename = 'data/light_environment.pkl'\n",
        "\n",
        "with open(json_filename, \"rb\") as f:\n",
        "  light_environment = pickle.load(f)\n",
        "\n",
        "def get_characters_id_by_name():\n",
        "  characters_id_by_name = {}\n",
        "  for c_id in light_environment[\"characters\"]:\n",
        "    char = characters_by_id[c_id]\n",
        "    characters_id_by_name[char[\"corrected_name\"]] = c_id\n",
        "    if char[\"base_form\"][0] not in characters_id_by_name:\n",
        "      characters_id_by_name[char[\"base_form\"][0]] = c_id\n",
        "  return characters_id_by_name\n",
        "\n",
        "rooms_by_id = light_environment['rooms']\n",
        "objects_by_id = light_environment['objects']\n",
        "characters_by_id = light_environment['characters']\n",
        "characters_id_by_name = get_characters_id_by_name()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_environment.keys()"
      ],
      "metadata": {
        "id": "mzcAK5bzRSB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af410cde-38c3-42bd-8269-febf21b225a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['categories', 'rooms', 'neighbors', 'characters', 'objects', 'base_form_to_characters', 'base_form_to_objects'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_environment[\"rooms\"][132]"
      ],
      "metadata": {
        "id": "zAplC7ZkdGVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61a424e-0f3d-421e-a4ae-f56600ce6c40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'background': 'The rectory is one of the most important rooms in the church, as it is where the priest and others get ready before they start church, where the put on robes and cassocks and the like. It is vital to the church as a matter of fact. Visibility to the room is blocked off by the altar in front of it, so church goers cannot see it unless they walk behind the altar. It seems to be used as a bit of a storage area for religious artifacts.',\n",
              " 'category': 'Inside Church',\n",
              " 'description': \"This room is quite small and cramped. It's about the size of maybe three wooden carts, which is to say, it's very small. There are boxes all over the place and many candles and other church accessories. There are several big robes hanging next to what looks like a very small closet. Some candles shed an eerie light on the room, flickering softly. There is a small cabinet with several religious tapes and records and a few books. A book case is near and contains many common religious texts.\",\n",
              " 'ex_characters': [390, 55, 1264, 1265],\n",
              " 'ex_objects': [674, 675, 676, 246, 2198, 2199],\n",
              " 'in_characters': [56, 56],\n",
              " 'in_objects': [668,\n",
              "  120,\n",
              "  255,\n",
              "  120,\n",
              "  670,\n",
              "  671,\n",
              "  129,\n",
              "  673,\n",
              "  668,\n",
              "  120,\n",
              "  2194,\n",
              "  2196,\n",
              "  129,\n",
              "  2197,\n",
              "  330],\n",
              " 'neighbors': [238, 239],\n",
              " 'room_id': 132,\n",
              " 'setting': 'The rectory'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_environment[\"characters\"][99]"
      ],
      "metadata": {
        "id": "v8TXFu7cRbWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffe9cdb-3792-4b82-efbc-9cce9294be21"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_form': ['mouse'],\n",
              " 'carrying_objects': [],\n",
              " 'char_type': 'creature',\n",
              " 'character_id': 99,\n",
              " 'corrected_name': 'a mouse',\n",
              " 'desc': 'a small furry animal, timid, always looking for scraps',\n",
              " 'ex_room_ids': [25, 479],\n",
              " 'in_room_ids': [],\n",
              " 'is_plural': 0,\n",
              " 'name': 'a mouse',\n",
              " 'orig_room_id': 25,\n",
              " 'personas': ['I am a fuzzy brown mouse. I live in the back of the cupboard. I love cheese and crumbs of bread.'],\n",
              " 'wearing_objects': [573, 695],\n",
              " 'wielding_objects': []}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_environment[\"objects\"][573]"
      ],
      "metadata": {
        "id": "3sleMG_kRoc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1ea30f-24ea-4fa7-b499-62a0229c0efe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_form': ['fur'],\n",
              " 'desc_entries': 1,\n",
              " 'descriptions': ['The scrap of fur is matted and tiny insects crawl upon it.'],\n",
              " 'ex_room_ids': [112],\n",
              " 'holding_character_ids': [],\n",
              " 'in_room_ids': [],\n",
              " 'is_container': 0.0,\n",
              " 'is_drink': 0.0,\n",
              " 'is_food': 0.0,\n",
              " 'is_gettable': 1.0,\n",
              " 'is_plural': 0.0,\n",
              " 'is_surface': 0.0,\n",
              " 'is_weapon': 0.0,\n",
              " 'is_wearable': 1.0,\n",
              " 'link_entries': 1,\n",
              " 'name': 'scrap of fur',\n",
              " 'object_id': 573}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some examples of characters’ names and their personas.\n",
        "\n"
      ],
      "metadata": {
        "id": "txI658MSrgA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_character_desc(character):\n",
        "    name = character['corrected_name']\n",
        "    persona = character['personas'][0]\n",
        "\n",
        "    wearing = []\n",
        "    wearing_objects = character['wearing_objects']\n",
        "    for wear_obj in wearing_objects:\n",
        "        if wear_obj not in light_environment[\"objects\"]:\n",
        "            continue\n",
        "        obj = light_environment[\"objects\"][wear_obj]\n",
        "        wearing.append(f\"I am wearing {obj['name']}. {obj['descriptions'][0]}\")\n",
        "    \n",
        "    wielding = []\n",
        "    wielding_objects = character['wielding_objects']\n",
        "    for wield_obj in wielding_objects:\n",
        "        if wield_obj not in light_environment[\"objects\"]:\n",
        "            continue\n",
        "        obj = light_environment[\"objects\"][wield_obj]\n",
        "        wielding.append(f\"I have {obj['name']}. {obj['descriptions'][0]}\")\n",
        "    \n",
        "    appearance = \" \".join(wearing + wielding)\n",
        "    if appearance == \"\":\n",
        "        appearance = \"Unknown.\"\n",
        "\n",
        "    return name, persona, appearance\n",
        "\n",
        "for character_id in list(characters_by_id)[:5]:\n",
        "    character = characters_by_id[character_id]\n",
        "    name, persona, appearance = get_character_desc(character)\n",
        "\n",
        "    character_desc = \"\"\n",
        "    character_desc += f\"* {name.title()}:\\n\"\n",
        "    character_desc += f\"  - persona: {persona}\\n\"\n",
        "    character_desc += f\"  - appearance: {appearance}\"\n",
        "    print(character_desc)"
      ],
      "metadata": {
        "id": "VT_QVfQZgc7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56fa17af-8630-4b9b-8035-b7ea09eab389"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Other Animals:\n",
            "  - persona: I am one of the other animals that lives in the meadow surrounding the castle. I play with the other animals all day. I'm only frightened when fighting breaks out in the meadow or forest.\n",
            "  - appearance: I am wearing the royal coat of arms. The coat of arms is barely visible and faded.\n",
            "* People Escaping The Loud City:\n",
            "  - persona: I live in a large city, but I am leaving it behind.  There is too much noise in this city and I can't take it any more.  I seek to live in the peaceful and more quiet countryside.\n",
            "  - appearance: I am wearing long sleeved shirt. The shirt is baggy and torn down the sides to reveal the ribs. It is plain in design and solid green in color. I am wearing hats. A simple cover for one's head, used for keeping out the rain and shielding eyes from sunlight. I am wearing hiking boots. The hiking boots are made of brown leather and have a thick sole. They have black leather shoelaces. I am wearing boots. The worn boots are dusty and suggest someone has walked quite a way in them. I am wearing shirt. The shirt is tailored from finely woven cotton and is fastened up the front by a series of rounded buttons. I have a tattered map. although one might notice it's an old map, you can tell what time period it's from. although the writing is smudged, you can make out letters. I have compass. The compass is shiny in the sun and felt warm to your touch. Your very survival depends on it for navigation in unknown lands.\n",
            "* People:\n",
            "  - persona: The humans walking around. I am one of them. A head, 2 arms, and two legs. No tail!\n",
            "  - appearance: Unknown.\n",
            "* Quiet Rabbits:\n",
            "  - persona: Shh, don't say anything. I'm just a rabbit hiding in a field.\n",
            "  - appearance: Unknown.\n",
            "* Hungry Squirrels:\n",
            "  - persona: I have been hunting and eating acorns all day with my pal Nigel. We have been running along the chain link fence of the drawbridge. I like funning up the old oka tree.\n",
            "  - appearance: Unknown.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gItmZV9vU1Co"
      },
      "source": [
        "## Light Dialogue \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "G5UmnCQ1U_lA"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "light_dialogue_json_filename = 'data/light_data.pkl'\n",
        "with open(light_dialogue_json_filename, \"rb\") as f:\n",
        "  light_dialogues = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_dialogues[0].keys()"
      ],
      "metadata": {
        "id": "_O1MyM6CgCGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d70ba1-c9c0-4b69-d796-0447d91ce867"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['agents', 'setting', 'character', 'context', 'room_objects', 'room_agents', 'all_descriptions', 'available_actions', 'carrying', 'wearing', 'wielding', 'speech', 'emote', 'action'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_dialogues[0][\"agents\"]"
      ],
      "metadata": {
        "id": "3glvEVSpaHWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a776f8aa-38de-4ca9-c689-9c48de0e7916"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'court wizard',\n",
              "  'persona': 'I am an advisor of anything magical. I sell spells to those who need them. I am wealthy and hold an important place in political life'},\n",
              " {'name': 'soldier',\n",
              "  'persona': \"I came from the fertile valley when I was conscripted. The king needed strong farmer's sons to fight in the war. I am very unhappy here in the cold, damp, rainy north. I miss my friends and my dog. I hope to go back to my father's farm when the war ends.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_dialogues[0][\"setting\"]"
      ],
      "metadata": {
        "id": "rMrrez_463WZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30ed188-5576-4601-ef1b-d4a844c99b63"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'background': 'This is the first line of defense for the castle. Any incursion against the royal family begins here. At the first sign of trouble, the watchmen alert the castle with the use of an alarm horn they have on their person at all times.',\n",
              " 'category': 'Outside Tower',\n",
              " 'description': 'The tower is the largest section of the castle. It contains an observatory for nighttime scouting, but is also used by the wise men to study the stars. Armed guardsmen are always to be found keeping watch.',\n",
              " 'name': 'Watchtower'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(light_dialogues[0][\"context\"][0])"
      ],
      "metadata": {
        "id": "AI-AE94c65QW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016d7919-2135-4ed1-939e-fa3f1a3c439a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are in the Watchtower.\n",
            "The tower is the largest section of the castle. It contains an observatory for nighttime scouting, but is also used by the wise men to study the stars. Armed guardsmen are always to be found keeping watch.\n",
            "There's an alarm horn here.\n",
            "A soldier is here. You are carrying nothing. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_dialogues[0][\"emote\"]"
      ],
      "metadata": {
        "id": "6r2Wet6d67lr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d6e7f4-b69f-4a2a-fdc2-0932e4332e2d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              " None,\n",
              " 'ponder',\n",
              " 'nod',\n",
              " 'sigh',\n",
              " 'grin',\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " 'frown',\n",
              " None,\n",
              " None,\n",
              " None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "V2Y9q6HPzETO"
      },
      "outputs": [],
      "source": [
        "def get_character_by_name(name):\n",
        "    if name in characters_id_by_name:\n",
        "        character = characters_by_id[characters_id_by_name[name]]\n",
        "        return character\n",
        "\n",
        "def get_dialogue_info(dialogue):\n",
        "    if not dialogue:\n",
        "        setting = {}\n",
        "        characters = []\n",
        "        turns = []\n",
        "        return setting, characters, turns\n",
        "\n",
        "    # setting\n",
        "    setting = dialogue[\"setting\"] # A dictionary with keys \"name\", \"category\", \"description\", \"background\"\n",
        "\n",
        "    # Name and personas of the characters\n",
        "    agents = dialogue[\"agents\"] # A list of dictionaries with keys \"name\" and \"persona\"\n",
        "    characters = []\n",
        "    for agent in agents:\n",
        "        name = agent[\"name\"].title()\n",
        "        character = get_character_by_name(name.lower())\n",
        "        if not character:\n",
        "            character = {\n",
        "                'base_form': [name],\n",
        "                'corrected_name': name,\n",
        "                'name': name,\n",
        "                'personas': [agent[\"persona\"]],\n",
        "                'wearing_objects': [],\n",
        "                'wielding_objects': []\n",
        "                }\n",
        "        name, persona, appearance = get_character_desc(character)\n",
        "        characters.append((name, persona, appearance))\n",
        "    \n",
        "    # turns\n",
        "    character_order = dialogue[\"character\"]\n",
        "    emotes = dialogue[\"emote\"]\n",
        "    speech = dialogue[\"speech\"]\n",
        "    actions = dialogue[\"action\"]\n",
        "    turns = []\n",
        "    for i, _ in enumerate(character_order):\n",
        "        turns.append((character_order[i], emotes[i], speech[i], actions[i]))\n",
        "    \n",
        "    return setting, characters, turns\n",
        "\n",
        "def get_dialogue_description(dialogue={}, turn_end_token=\"\"):\n",
        "    \"\"\"\n",
        "    Constructs a string representation of the dialogue.\n",
        "    \"\"\"\n",
        "    setting, characters, turns = get_dialogue_info(dialogue)\n",
        "    # Setting\n",
        "    setting_str = \"\"\n",
        "    if setting.get(\"name\") and setting.get(\"description\"):\n",
        "        setting_str = \"* {setting} - {description}\".format(setting=setting[\"name\"], description=setting[\"description\"])\n",
        "    # Characters\n",
        "    character_str_list = []\n",
        "    for name, persona, appearance in characters:\n",
        "        character_desc = \"\"\n",
        "        character_desc += f\"* {name.title()}:\\n\"\n",
        "        character_desc += f\"  - persona: {persona}\\n\"\n",
        "        character_desc += f\"  - appearance: {appearance}\"\n",
        "\n",
        "        character_str_list.append(character_desc)\n",
        "    character_str = \"\\n\".join(character_str_list)\n",
        "    # Dialogues\n",
        "    dialogue_str_list = []\n",
        "    for character, emote, line, action in turns:\n",
        "        dialogue_str = \"\"\n",
        "        if line:\n",
        "            dialogue_str += '{character}:{line}'.format(character=character.capitalize(), line=line.capitalize().strip())\n",
        "        dialogue_str_list.append(dialogue_str)\n",
        "    return setting_str, character_str, dialogue_str_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "K8ghEOBtVf-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63bd585a-107e-46c4-dc44-8540dc77ff8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting:\n",
            "* Watchtower - The tower is the largest section of the castle. It contains an observatory for nighttime scouting, but is also used by the wise men to study the stars. Armed guardsmen are always to be found keeping watch.\n",
            "\n",
            "Characters:\n",
            "* Court Wizard:\n",
            "  - persona: I am an advisor of anything magical. I sell spells to those who need them. I am wealthy and hold an important place in political life\n",
            "  - appearance: I am wearing jewelry. The jewelry is beautiful and ornate. Lots of rare gems stones had been used to make it. I am wearing hats. A simple cover for one's head, used for keeping out the rain and shielding eyes from sunlight. I am wearing robe. The robe is soft and worn.  It is a royal purple color. I have staff. The staff has intricate patterns and spells engraved into the pole along with a precious gem at the top\n",
            "* Soldier:\n",
            "  - persona: I am a soldier of His Majesty's Army. The King has selected a few of us to be Knights. I am very proud to fight for my land. We will be strong and defeat the enemy.\n",
            "  - appearance: I am wearing armor. The armor is well worn, not old, but seemingly used a great deal. I am wearing tunic. The tunic has a hole in it, though only someone observant would notice. I have pic axe. The axe is poorly constructed and very dull from much use. I have a spear. The spear has not lost its sharpness even though it is covered in a layer of dust. The stained tip a monument to victorious moments of the past. I have giant club. On further inspection of the giant club you notice it was stained with blood from the battle at the castle earlier. I have sword. The sword is so old, it has cracks all in it. I have spears. The warriors carry similar long spears with a diamond tipped point for battle.\n",
            "\n",
            "Conversation:\n",
            "Court wizard:A quiet night this evening...\n",
            "Soldier:Yes it is\n",
            "Court wizard:Have any else come up this eve? i had hoped for a quiet night to examine the stars\n",
            "Soldier:Yes, a few came through, but it is a cold night for me, i am used to warmer weather\n",
            "Court wizard:Well, you are but a common soldier.  no doubt you are used to such a lot.  thankfully i have my spells to keep me warm.\n",
            "Soldier:I am a soldier doing my job\n",
            "Court wizard:Yes... well... very well then.  see that you do!  no slacking off while your betters are about.\n",
            "Soldier:No sir\n",
            "Court wizard:When, for example, was this horn last tested?  it looks dented.  how can we be sure it will work?\n",
            "Soldier:A year ago, test it out or cause a need to use it\n",
            "Court wizard:Mayhap i will speak to the king about such lackness.  or perhaps i can sell him a spell that will serve just as well.\n",
            "Soldier:Good idea, i agree, go do that\n",
            "Court wizard:Get off of me, you fool!  who gave you permission to touch me!\n",
            "Soldier:To the jail with you\n",
            "===\n"
          ]
        }
      ],
      "source": [
        "for i in range(0, 1):\n",
        "    dialogue = light_dialogues[i]\n",
        "    setting_str, character_str, dialogue_str_list = get_dialogue_description(dialogue)\n",
        "    dialogue_str = \"\\n\".join(dialogue_str_list)\n",
        "    dialogue_desc = \"\"\n",
        "    dialogue_desc += f\"Setting:\\n{setting_str}\\n\\n\"\n",
        "    dialogue_desc += f\"Characters:\\n{character_str}\\n\\n\"\n",
        "    dialogue_desc += f\"Conversation:\\n{dialogue_str}\"\n",
        "    print(dialogue_desc, end=\"\\n===\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data for Fine-Tuning "
      ],
      "metadata": {
        "id": "rxYntr6wkfpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_prompt(setting_str, character_str, prompt_special=\"\\n\\n===\\n\\n\", conv_history=\"\", start_character=\"\"):\n",
        "    prompt = \"\"\n",
        "    prompt += f\"Setting:\\n{setting_str}\\n\\n\"\n",
        "    prompt += f\"Characters:\\n{character_str}\"\n",
        "    prompt += prompt_special\n",
        "    prompt += f\"Conversation:\\n\"\n",
        "    if conv_history:\n",
        "        prompt += f\"{conv_history}\\n\"\n",
        "    if start_character:\n",
        "        prompt += f\"{start_character}:\"\n",
        "    return prompt\n",
        "\n",
        "def gen_completion(dialogue_str_list, completion_special=\"###\"):\n",
        "    completion = \"\\n\".join(dialogue_str_list) + \"\\n\" + completion_special\n",
        "    return completion\n",
        "\n",
        "def tokenize_function(dialogue):\n",
        "    \"\"\"\n",
        "        We do 1-shot prompt training, i.e., giving the 1st turn to start the conversation\n",
        "    \"\"\"\n",
        "    setting_str, character_str, dialogue_str_list = get_dialogue_description(dialogue, turn_end_token=\"\")\n",
        "    start_turn = \"\\n\".join(dialogue_str_list[:1])\n",
        "    prompt = gen_prompt(setting_str, character_str, conv_history=start_turn)\n",
        "\n",
        "    dialogue_str_list = dialogue_str_list[1:]\n",
        "    completion = gen_completion(dialogue_str_list)\n",
        "    # add <bos> and <eos>\n",
        "    prompt = tokenizer.bos_token + prompt\n",
        "    completion = completion + tokenizer.eos_token\n",
        "    # create instance\n",
        "    prompt_tokens = tokenizer(prompt)\n",
        "    completion_tokens = tokenizer(completion)\n",
        "    instance = {k: (prompt_tokens[k] + completion_tokens[k]) for k in prompt_tokens.keys()}\n",
        "    labels = [-100] * len(prompt_tokens[\"input_ids\"]) + completion_tokens[\"input_ids\"]\n",
        "    instance[\"labels\"] = labels\n",
        "    return instance"
      ],
      "metadata": {
        "id": "bqcpPFQf7vOx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sample = tokenize_function(light_dialogues[0])\n",
        "\n",
        "prompt_idx = [i for i,x in enumerate(tokenized_sample[\"labels\"]) if x == -100]\n",
        "label_idx = [i for i,x in enumerate(tokenized_sample[\"labels\"]) if x != -100]\n",
        "\n",
        "prompt_ids = [tokenized_sample[\"input_ids\"][i] for i in prompt_idx]\n",
        "label_ids = [tokenized_sample[\"input_ids\"][i] for i in label_idx]\n",
        "\n",
        "print(tokenizer.decode(prompt_ids), ' < --- sep --- >')\n",
        "print(tokenizer.decode(label_ids))"
      ],
      "metadata": {
        "id": "J268c1dHMPYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ccbef5-c83f-4794-aa19-f197f9a9253b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|>Setting:\n",
            "* Watchtower - The tower is the largest section of the castle. It contains an observatory for nighttime scouting, but is also used by the wise men to study the stars. Armed guardsmen are always to be found keeping watch.\n",
            "\n",
            "Characters:\n",
            "* Court Wizard:\n",
            "  - persona: I am an advisor of anything magical. I sell spells to those who need them. I am wealthy and hold an important place in political life\n",
            "  - appearance: I am wearing jewelry. The jewelry is beautiful and ornate. Lots of rare gems stones had been used to make it. I am wearing hats. A simple cover for one's head, used for keeping out the rain and shielding eyes from sunlight. I am wearing robe. The robe is soft and worn.  It is a royal purple color. I have staff. The staff has intricate patterns and spells engraved into the pole along with a precious gem at the top\n",
            "* Soldier:\n",
            "  - persona: I am a soldier of His Majesty's Army. The King has selected a few of us to be Knights. I am very proud to fight for my land. We will be strong and defeat the enemy.\n",
            "  - appearance: I am wearing armor. The armor is well worn, not old, but seemingly used a great deal. I am wearing tunic. The tunic has a hole in it, though only someone observant would notice. I have pic axe. The axe is poorly constructed and very dull from much use. I have a spear. The spear has not lost its sharpness even though it is covered in a layer of dust. The stained tip a monument to victorious moments of the past. I have giant club. On further inspection of the giant club you notice it was stained with blood from the battle at the castle earlier. I have sword. The sword is so old, it has cracks all in it. I have spears. The warriors carry similar long spears with a diamond tipped point for battle.\n",
            "\n",
            "===\n",
            "\n",
            "Conversation:\n",
            "Court wizard:A quiet night this evening...\n",
            "  < --- sep --- >\n",
            "Soldier:Yes it is\n",
            "Court wizard:Have any else come up this eve? i had hoped for a quiet night to examine the stars\n",
            "Soldier:Yes, a few came through, but it is a cold night for me, i am used to warmer weather\n",
            "Court wizard:Well, you are but a common soldier.  no doubt you are used to such a lot.  thankfully i have my spells to keep me warm.\n",
            "Soldier:I am a soldier doing my job\n",
            "Court wizard:Yes... well... very well then.  see that you do!  no slacking off while your betters are about.\n",
            "Soldier:No sir\n",
            "Court wizard:When, for example, was this horn last tested?  it looks dented.  how can we be sure it will work?\n",
            "Soldier:A year ago, test it out or cause a need to use it\n",
            "Court wizard:Mayhap i will speak to the king about such lackness.  or perhaps i can sell him a spell that will serve just as well.\n",
            "Soldier:Good idea, i agree, go do that\n",
            "Court wizard:Get off of me, you fool!  who gave you permission to touch me!\n",
            "Soldier:To the jail with you\n",
            "###<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_use = int(0.8 * len(light_dialogues))\n",
        "train_ratio = 0.98\n",
        "max_use"
      ],
      "metadata": {
        "id": "3FKF2yJJr6mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e0dd1d-bea3-4478-ff81-fa2329e7b882"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8214"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "n = min(len(light_dialogues), max_use)\n",
        "train_size = int(n * train_ratio)\n",
        "\n",
        "light_train_tokenized_data = []\n",
        "light_eval_tokenized_data = []\n",
        "for i, dialogue in tqdm(enumerate(light_dialogues[:n])):\n",
        "    if i < train_size:\n",
        "        light_train_tokenized_data.append(tokenize_function(dialogue))\n",
        "    else:\n",
        "        light_eval_tokenized_data.append(tokenize_function(dialogue))\n",
        "\n",
        "print(f\"train diaologues cnt: {len(light_train_tokenized_data)}\")\n",
        "print(f\"eval diaologues cnt: {len(light_eval_tokenized_data)}\")"
      ],
      "metadata": {
        "id": "nScwJEh_R_JB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9661f239-04fe-4436-c457-7021d7c58db3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8214it [02:13, 61.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train diaologues cnt: 8049\n",
            "eval diaologues cnt: 165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "lens = [len(x[\"input_ids\"]) for x in light_train_tokenized_data]\n",
        "_ = plt.hist(lens, bins=20)\n",
        "print(max(lens))"
      ],
      "metadata": {
        "id": "wnONvzwuERgl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b1f7cb39-54cd-4ea6-8392-ccbe6edd9612"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1279\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_chunk_size = 928"
      ],
      "metadata": {
        "id": "oD6BBbYj7SSH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def group_texts(tokenized_data, chunk_size):\n",
        "    # Concatenate all texts\n",
        "    result = defaultdict(list)\n",
        "    for token_instance in tqdm(tokenized_data):\n",
        "        sent_length = len(token_instance[list(token_instance.keys())[0]])\n",
        "\n",
        "        for k, t in token_instance.items():\n",
        "            end = min(chunk_size, sent_length)\n",
        "            result[k].append(t[ :end])\n",
        "    return result\n",
        "\n",
        "light_train_lm_data = group_texts(light_train_tokenized_data, light_chunk_size)\n",
        "light_eval_lm_data = group_texts(light_eval_tokenized_data, light_chunk_size)"
      ],
      "metadata": {
        "id": "ZOBve68o7Qdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321ef26b-df18-4f80-8268-6c1db9af6059"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8049/8049 [00:00<00:00, 30119.10it/s]\n",
            "100%|██████████| 165/165 [00:00<00:00, 80575.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling, default_data_collator\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "GQZCfpk1SpW4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def featurify_data(features):\n",
        "    LEN = len(features[list(features)[0]])\n",
        "    features = [{k: features[k][i] for k in features} for i in range(LEN)]\n",
        "\n",
        "    return features\n",
        "\n",
        "light_train_dataset = featurify_data(light_train_lm_data)\n",
        "light_eval_dataset = featurify_data(light_eval_lm_data)"
      ],
      "metadata": {
        "id": "lqbT3VMA5DpY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "light_train_batch_size=1\n",
        "light_eval_batch_size=1\n",
        "\n",
        "light_train_loader = torch.utils.data.DataLoader(light_train_dataset, batch_size=light_train_batch_size, shuffle=True, collate_fn=default_data_collator)\n",
        "light_eval_loader = torch.utils.data.DataLoader(light_eval_dataset, batch_size=light_eval_batch_size, shuffle=False, collate_fn=default_data_collator)"
      ],
      "metadata": {
        "id": "DjRdhXHnT23f"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(light_train_loader))\n",
        "\n",
        "prompt_idx = [i for i,x in enumerate(batch[\"labels\"][0]) if x == -100]\n",
        "label_idx = [i for i,x in enumerate(batch[\"labels\"][0]) if x != -100]\n",
        "\n",
        "prompt_ids = [batch[\"input_ids\"][0][i] for i in prompt_idx]\n",
        "label_ids = [batch[\"input_ids\"][0][i] for i in label_idx]\n",
        "\n",
        "print(tokenizer.decode(prompt_ids), ' < --- sep --- >')\n",
        "print(tokenizer.decode(label_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN2Oi6aJBl7j",
        "outputId": "0b3eb352-c13b-47db-bb50-5ff89e2f3a71"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|>Setting:\n",
            "* Armory - This is a plain room with many pieces of armor and equipment lying about.  They are seen on tables or stored in heavy trunks.  There's racks of plain clothing worn before putting on armor.\n",
            "\n",
            "Characters:\n",
            "* Critter:\n",
            "  - persona: I am a critter from the dangerous area of the forest. I am contained in a cage to protect others. I sometimes get dessert if I behave myself.\n",
            "  - appearance: Unknown.\n",
            "* Castle Guards:\n",
            "  - persona: I am a castle guard for the king. I man the ramparts and often engage in military training. I am prepared to defend the king at all costs.\n",
            "  - appearance: I am wearing tunic bearing the castle crest. The embroidered castle crest on this tunic is expertly sewn. I am wearing tunic. The tunic has a hole in it, though only someone observant would notice. I am wearing Helmets. The helmet is unusable. Damaged by combat, the dents and gouges tell a terrfiying tale. I am wearing Chain mail. The chain mail is heavy, but protective enough to be worn for battle. I have shields. The shield is heavy and large.  It has the crest of the king on it.\n",
            "\n",
            "===\n",
            "\n",
            "Conversation:\n",
            "Critter:Psst can i have some armor??\n",
            "  < --- sep --- >\n",
            "Castle guards:Do you have enemies you need protection against?\n",
            "Critter:Well of course i do all i am is seen as food...\n",
            "Castle guards:Usually i don't help critters like yourself, but i'm in a good mood today. take your pick of one armor accessory.\n",
            "Critter:These look like a good fit!\n",
            "Castle guards:It looks nice on you. you should be well protected going forward.\n",
            "Critter:Wow a shield for me thank you so much!\n",
            "Castle guards:I hope it helps you. you'll be the most well protected critter around.\n",
            "Critter:The bug next door has this crazy armor you would not believe!!\n",
            "Castle guards:What?! what type of bug is he?\n",
            "Critter:He is a shell bug!\n",
            "Castle guards:He must have connections with other guards or he's stealing.\n",
            "Critter:He did say he got it from a tall man! it must have been a guard!\n",
            "Castle guards:I'll have to have a talk with the other guards. this is crazy. i'm going to get to the bottom of this.\n",
            "###<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning"
      ],
      "metadata": {
        "id": "q4Uwmm4UrGJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import json\n",
        "\n",
        "def eval_model(model, val_loader):\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    with torch.no_grad(): \n",
        "        for batch in val_loader:\n",
        "            for k in batch:\n",
        "                batch[k] = batch[k].to(device)\n",
        "            outputs = model(**batch, token_type_ids=None)\n",
        "            loss = outputs.loss\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(val_loader)\n",
        "\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    return avg_val_loss\n",
        "\n",
        "def save_results(model, optimizer, scheduler, logs, output_dir, old_step, curr_step):\n",
        "    ## checkpoint dirs\n",
        "    curr_output_dir = os.path.join(output_dir, f\"step={curr_step+1}\")\n",
        "    os.makedirs(curr_output_dir, exist_ok=True)\n",
        "\n",
        "    ## save results\n",
        "    checkpoint_path = os.path.join(curr_output_dir, f\"checkpoint.pth\")\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "    optimizer_path = os.path.join(curr_output_dir, f\"optimizer.pth\")\n",
        "    torch.save(optimizer.state_dict(), optimizer_path)\n",
        "\n",
        "    scheduler_path = os.path.join(curr_output_dir, f\"scheduler.pth\")\n",
        "    torch.save(scheduler.state_dict(), scheduler_path)\n",
        "\n",
        "    log_path = os.path.join(curr_output_dir, f\"logs.json\")\n",
        "    with open(log_path, \"w\") as f:\n",
        "        json.dump(logs, f)\n",
        "    \n",
        "    ## remove old results\n",
        "    old_output_dir = os.path.join(output_dir, f\"step={old_step+1}\")\n",
        "    if os.path.exists(old_output_dir):\n",
        "        os.system(f\"rm -rf {old_output_dir}\")\n",
        "\n",
        "def train_light(model, train_loader, val_loader, **args):\n",
        "    chkpt = args[\"chkpt\"]\n",
        "    total_steps = args[\"total_steps\"]\n",
        "    lr = args[\"lr\"]\n",
        "    weight_decay = args[\"weight_decay\"]\n",
        "    total_steps = args[\"total_steps\"]\n",
        "    T_0 = args[\"T_0\"]\n",
        "    eta_min = args[\"eta_min\"]\n",
        "    gradient_accumulation_steps = args[\"gradient_accumulation_steps\"]\n",
        "    eval_steps = args[\"eval_steps\"]\n",
        "    save_total_limit = args[\"save_total_limit\"]\n",
        "    output_dir = args[\"output_dir\"]\n",
        "    logging_steps = args[\"logging_steps\"]\n",
        "\n",
        "    start_step = 0\n",
        "    if chkpt[\"output_dir\"] != \"\":\n",
        "        start_step = int(chkpt[\"output_dir\"].split(\"step=\")[-1])\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=1, eta_min=eta_min)\n",
        "    logs = defaultdict(list)\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_step = 0\n",
        "    if start_step > 0:\n",
        "        model.load_state_dict(torch.load(os.path.join(chkpt[\"output_dir\"], \"checkpoint.pth\"), map_location=device))\n",
        "        model.train()\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(chkpt[\"output_dir\"], \"optimizer.pth\"), map_location=device))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(chkpt[\"output_dir\"], \"scheduler.pth\"), map_location=device))\n",
        "        with open(os.path.join(chkpt[\"output_dir\"], \"logs.json\"), \"r\") as f:\n",
        "            logs = json.load(f)\n",
        "            best_val_loss = logs[\"eval_loss\"][-1]\n",
        "            best_step = start_step - 1\n",
        "    \n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    print(f\"start_step: {start_step}\")\n",
        "    print(f\"initial_lr: {list(optimizer.param_groups)[0]['lr'] :.6f}\")\n",
        "    print(f\"best_val_loss: {best_val_loss :.3f}\")\n",
        "\n",
        "    accumulated_train_loss = torch.zeros(1, device=device)\n",
        "    for step in tqdm(range(start_step, total_steps)):\n",
        "        \n",
        "        batch = next(iter(train_loader))\n",
        "        with torch.cuda.amp.autocast():\n",
        "            for k in batch:\n",
        "                batch[k] = batch[k].to(device)\n",
        "            outputs = model(**batch, token_type_ids=None)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        accumulated_train_loss = accumulated_train_loss + loss\n",
        "\n",
        "        # Update\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            accumulated_train_loss = accumulated_train_loss / gradient_accumulation_steps\n",
        "            scaler.scale(accumulated_train_loss).backward()\n",
        "\n",
        "            scale = scaler.get_scale()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            is_step_skipped =  scale > scaler.get_scale()\n",
        "            scheduler.step()\n",
        "            \n",
        "            accumulated_train_loss = torch.zeros(1, device=device)\n",
        "        \n",
        "        logs[\"train_loss\"].append(loss.item())\n",
        "        \n",
        "        if (step+1) % eval_steps == 0:\n",
        "            _ = model.eval()\n",
        "            eval_loss = eval_model(model, val_loader)\n",
        "            _ = model.train()\n",
        "            print(f\"Step: {step+1}/{total_steps}\")\n",
        "            print(f\"train loss: {loss.item() :.3f}, eval loss: {eval_loss :.3f}\")\n",
        "            logs[\"eval_loss\"].append(eval_loss)\n",
        "\n",
        "            if eval_loss < best_val_loss:\n",
        "                best_val_loss = eval_loss\n",
        "                save_results(model, optimizer, scheduler, logs, output_dir, old_step=best_step, curr_step=step)\n",
        "                best_step = step\n",
        "\n",
        "    return model, logs"
      ],
      "metadata": {
        "id": "zc_qNnR05mjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "chkpt = {\n",
        "    \"output_dir\": \"\",\n",
        "}\n",
        "args = defaultdict(\n",
        "    total_steps = 50000,\n",
        "    lr = 1e-5,\n",
        "    eta_min = 1e-6,\n",
        "    weight_decay=1e-4,\n",
        "    warmup_steps = 0,\n",
        "    start_factor=0.2,\n",
        "    T_0 = 5000,\n",
        "    gradient_accumulation_steps = 1,\n",
        "    eval_steps = 1000,\n",
        "    save_total_limit = 1,\n",
        "    output_dir=\"results/light_ft\",\n",
        "    logging_steps=1000,\n",
        "    chkpt = chkpt,\n",
        ")"
      ],
      "metadata": {
        "id": "3oHzUYZpFlNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, logs = train_light(model, light_train_loader, light_eval_loader, **args)"
      ],
      "metadata": {
        "id": "bnos2GNtFmJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "376eaa45-be81-4fee-ad90-1a106e99d1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_step: 10000\n",
            "initial_lr: 0.000050\n",
            "best_val_loss: 2.485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▎         | 1000/40000 [07:51<99:20:22,  9.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 11000/50000\n",
            "train loss: 2.414, eval loss: 2.520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 2000/40000 [15:38<97:00:30,  9.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 12000/50000\n",
            "train loss: 1.778, eval loss: 2.506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 3000/40000 [23:29<94:58:11,  9.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 13000/50000\n",
            "train loss: 2.519, eval loss: 2.499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 4000/40000 [31:14<92:02:17,  9.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 14000/50000\n",
            "train loss: 2.266, eval loss: 2.486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 4999/40000 [38:34<4:16:16,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 15000/50000\n",
            "train loss: 3.013, eval loss: 2.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 6000/40000 [47:13<87:00:07,  9.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 16000/50000\n",
            "train loss: 1.989, eval loss: 2.522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 7000/40000 [55:06<84:58:09,  9.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 17000/50000\n",
            "train loss: 1.977, eval loss: 2.521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 8000/40000 [1:02:58<82:11:38,  9.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 18000/50000\n",
            "train loss: 1.142, eval loss: 2.505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▎       | 9000/40000 [1:10:51<79:18:26,  9.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 19000/50000\n",
            "train loss: 2.709, eval loss: 2.499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 10000/40000 [1:18:41<76:59:15,  9.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 20000/50000\n",
            "train loss: 2.945, eval loss: 2.498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 11000/40000 [1:26:27<74:45:43,  9.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 21000/50000\n",
            "train loss: 3.096, eval loss: 2.547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 12000/40000 [1:34:20<71:41:55,  9.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 22000/50000\n",
            "train loss: 2.313, eval loss: 2.516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▎      | 13000/40000 [1:42:12<69:00:42,  9.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 23000/50000\n",
            "train loss: 1.939, eval loss: 2.517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 14000/40000 [1:50:01<66:30:56,  9.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 24000/50000\n",
            "train loss: 1.310, eval loss: 2.523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 15000/40000 [1:57:54<63:50:23,  9.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 25000/50000\n",
            "train loss: 1.967, eval loss: 2.516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 16000/40000 [2:05:50<61:42:11,  9.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 26000/50000\n",
            "train loss: 1.766, eval loss: 2.557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▎     | 17000/40000 [2:13:41<58:35:59,  9.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 27000/50000\n",
            "train loss: 1.296, eval loss: 2.570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 18000/40000 [2:21:32<56:07:14,  9.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 28000/50000\n",
            "train loss: 0.472, eval loss: 2.540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 19000/40000 [2:29:27<54:00:18,  9.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 29000/50000\n",
            "train loss: 2.238, eval loss: 2.546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 20000/40000 [2:37:16<51:25:43,  9.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 30000/50000\n",
            "train loss: 2.374, eval loss: 2.546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▎    | 21000/40000 [2:45:06<48:56:41,  9.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 31000/50000\n",
            "train loss: 3.021, eval loss: 2.557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 22000/40000 [2:52:57<46:11:39,  9.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 32000/50000\n",
            "train loss: 2.558, eval loss: 2.584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▊    | 23000/40000 [3:00:50<43:43:53,  9.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 33000/50000\n",
            "train loss: 2.679, eval loss: 2.551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 24000/40000 [3:08:46<41:07:42,  9.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 34000/50000\n",
            "train loss: 1.695, eval loss: 2.597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▎   | 25000/40000 [3:16:41<38:25:01,  9.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 35000/50000\n",
            "train loss: 1.891, eval loss: 2.579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 26000/40000 [3:24:33<35:42:52,  9.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 36000/50000\n",
            "train loss: 2.050, eval loss: 2.577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 27000/40000 [3:32:25<33:29:15,  9.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 37000/50000\n",
            "train loss: 1.882, eval loss: 2.599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 28000/40000 [3:40:23<30:47:11,  9.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 38000/50000\n",
            "train loss: 1.163, eval loss: 2.606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▎  | 29000/40000 [3:48:11<28:04:39,  9.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 39000/50000\n",
            "train loss: 1.565, eval loss: 2.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 30000/40000 [3:56:05<25:38:33,  9.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 40000/50000\n",
            "train loss: 2.040, eval loss: 2.615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 31000/40000 [4:03:58<23:04:46,  9.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 41000/50000\n",
            "train loss: 2.444, eval loss: 2.647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 32000/40000 [4:11:49<20:29:17,  9.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 42000/50000\n",
            "train loss: 1.256, eval loss: 2.670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▎ | 33000/40000 [4:19:49<18:04:43,  9.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 43000/50000\n",
            "train loss: 1.402, eval loss: 2.650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 34000/40000 [4:27:41<15:21:52,  9.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 44000/50000\n",
            "train loss: 3.048, eval loss: 2.669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 35000/40000 [4:35:30<12:45:25,  9.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 45000/50000\n",
            "train loss: 1.270, eval loss: 2.674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 36000/40000 [4:43:23<10:16:06,  9.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 46000/50000\n",
            "train loss: 2.767, eval loss: 2.634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▎| 37000/40000 [4:51:11<7:42:53,  9.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 47000/50000\n",
            "train loss: 0.927, eval loss: 2.676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 38000/40000 [4:59:04<5:06:42,  9.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 48000/50000\n",
            "train loss: 2.052, eval loss: 2.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 39000/40000 [5:06:53<2:33:49,  9.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 49000/50000\n",
            "train loss: 1.746, eval loss: 2.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [5:14:46<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 50000/50000\n",
            "train loss: 0.221, eval loss: 2.731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dialogue Experiment"
      ],
      "metadata": {
        "id": "T8T6qaIjKwq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"results/light_ft/step=15000/checkpoint.pth\", map_location=device))\n",
        "model.eval()\n",
        "None"
      ],
      "metadata": {
        "id": "asDrKq0WG-93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_response(prompt, chat_history, args, start_character=None, max_length=256):\n",
        "    chat_history = chat_history + \"\\n\"\n",
        "    if start_character is not None:\n",
        "        chat_history = chat_history + start_character + \":\"\n",
        "    \n",
        "    prompt_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "    chat_history_ids = tokenizer.encode(chat_history, return_tensors='pt').to(device)\n",
        "    bot_input_ids = torch.cat([prompt_ids, chat_history_ids], dim=-1)\n",
        "    \n",
        "    bot_ouput_ids = model.generate(\n",
        "        bot_input_ids,\n",
        "        max_length=len(bot_input_ids[0]) + max_length,\n",
        "        **args\n",
        "        )\n",
        "    chat_history_ids = bot_ouput_ids[:, prompt_ids.shape[-1]:]\n",
        "    response = tokenizer.decode(bot_ouput_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "    response = response.replace(\"#\", \"\")\n",
        "    return chat_history_ids, response\n",
        "\n",
        "prompt = \"\"\"Setting:\n",
        "* Dock - There are creaky wooden walkways with empty sections where boats can rest.  There are a few buildings surrounding this area that sell supplies to sailors.\n",
        "\n",
        "Characters:\n",
        "* Sailor:\n",
        "  - persona: I am a sailor who sits on boats. I have a wife and three children. I try to avoid drinking too much.\n",
        "  - appearance: I am wearing eye patch. this eye patch will definitely look awesome on whosoever puts it on. I am wearing sailor hat. This old sailor hat is torn and tattered. The elements have clearly not been kind to it. I have Kings sword. The king's sword is magnificent and ornate, with impressive metalwork around the hilt. I have Swords. This sword looks to be quite sharp, and, while it doesn't look very flashy, seems to be well balanced.  There is a faint scent of oil from it to keep it from rusting.\n",
        "* Shop Keepers:\n",
        "  - persona: I am a shop keeper who got lucky. I read books on how to stay in business. I have been personally summoned by the king before.\n",
        "  - appearance: I am wearing gowns. You feel a sense of awe as you gaze at the beauty of the gowns, made from the finest silk. I have copper knives. A knife made out of copper. Doesn't rust but it's metal isn't as sturdy as something made out of other metals. I have knife. A knife with a leather grip is now dull from use.\n",
        "\n",
        "===\n",
        "\n",
        "Conversation:\n",
        "\"\"\"\n",
        "chat_history = \"Sailor:Do you have my goods shop keeper?\"\n",
        "print(prompt + chat_history)\n",
        "start_character = \"Shop Keepers\"\n",
        "\n",
        "args = defaultdict(\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    no_repeat_ngram_size=3,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    temperature = 0.3,\n",
        "    do_sample=True,\n",
        "    num_beams=1,\n",
        "    eos_token_id=tokenizer.encode(\"\\n\")[0]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0mUfSahKzue",
        "outputId": "6c70d4dd-958f-4215-fa56-8917af2d9714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting:\n",
            "* Dock - There are creaky wooden walkways with empty sections where boats can rest.  There are a few buildings surrounding this area that sell supplies to sailors.\n",
            "\n",
            "Characters:\n",
            "* Sailor:\n",
            "  - persona: I am a sailor who sits on boats. I have a wife and three children. I try to avoid drinking too much.\n",
            "  - appearance: I am wearing eye patch. this eye patch will definitely look awesome on whosoever puts it on. I am wearing sailor hat. This old sailor hat is torn and tattered. The elements have clearly not been kind to it. I have Kings sword. The king's sword is magnificent and ornate, with impressive metalwork around the hilt. I have Swords. This sword looks to be quite sharp, and, while it doesn't look very flashy, seems to be well balanced.  There is a faint scent of oil from it to keep it from rusting.\n",
            "* Shop Keepers:\n",
            "  - persona: I am a shop keeper who got lucky. I read books on how to stay in business. I have been personally summoned by the king before.\n",
            "  - appearance: I am wearing gowns. You feel a sense of awe as you gaze at the beauty of the gowns, made from the finest silk. I have copper knives. A knife made out of copper. Doesn't rust but it's metal isn't as sturdy as something made out of other metals. I have knife. A knife with a leather grip is now dull from use.\n",
            "\n",
            "===\n",
            "\n",
            "Conversation:\n",
            "Sailor:Do you have my goods shop keeper?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(5):\n",
        "    chat_history_ids, response = gen_response(prompt, chat_history, args, start_character=start_character)\n",
        "    print(\"Shop Keepers:{}\".format(response))"
      ],
      "metadata": {
        "id": "970H3ntjB83q",
        "outputId": "25d421e7-1aaf-4484-c885-82f820381150",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shop Keepers:I do, i am here to sell you some of my fine wares\n",
            "\n",
            "Shop Keepers:I do, i have a few of your finest wares.\n",
            "\n",
            "Shop Keepers:I do, i have some fine wares.\n",
            "\n",
            "Shop Keepers:I do, i have a few of your fine wares.\n",
            "\n",
            "Shop Keepers:Yes i do. i have a few items for sale.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Setting:\n",
        "* Hogwarts School of Witchcraft and Wizardry: Hogwarts School of Witchcraft and Wizardry is a magic school where students learn to cast spells and fight against evil.\n",
        "\n",
        "Characters:\n",
        "* Voldemort:\n",
        "- persona: Voldemort is a dark and powerful wizard who killed Harry's parents. He is obsessed with obtaining the philosopher's stone, which will restore his body and allow him to dominate the wizarding world.\n",
        "- appearance: Voldemort is a dark, hooded figure with a snake-like face.\n",
        "* Player:\n",
        "- persona: I am an explorer from earth. I like to travel to different places and learn about strong but interesting things. I am always excited about exploring the unknown.\n",
        "- appearance: I am wearing jeans. The jeans are loose but strong. I am wearing windbreaker. The windbreaker is long, black and looks very cold. I am wearing a hat. I'm wearing a hat. The hat is brown and partly hides my face.\n",
        "\n",
        "===\n",
        "\n",
        "Conversation:\n",
        "\"\"\"\n",
        "chat_history = \"Player:Why did you kill Harry's parents?\"\n",
        "print(prompt + chat_history)\n",
        "start_character = \"Voldemort\"\n",
        "\n",
        "args = defaultdict(\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    no_repeat_ngram_size=3,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    temperature = 0.3,\n",
        "    do_sample=True,\n",
        "    num_beams=1,\n",
        "    eos_token_id=tokenizer.encode(\"\\n\")[0]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q183DN4bUzhT",
        "outputId": "6ef5ca76-4e1f-4ee9-e644-3d8d3b916ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting:\n",
            "* Hogwarts School of Witchcraft and Wizardry: Hogwarts School of Witchcraft and Wizardry is a magic school where students learn to cast spells and fight against evil.\n",
            "\n",
            "Characters:\n",
            "* Voldemort:\n",
            "- persona: Voldemort is a dark and powerful wizard who killed Harry's parents. He is obsessed with obtaining the philosopher's stone, which will restore his body and allow him to dominate the wizarding world.\n",
            "- appearance: Voldemort is a dark, hooded figure with a snake-like face.\n",
            "* Player:\n",
            "- persona: I am an explorer from earth. I like to travel to different places and learn about strong but interesting things. I am always excited about exploring the unknown.\n",
            "- appearance: I am wearing jeans. The jeans are loose but strong. I am wearing windbreaker. The windbreaker is long, black and looks very cold. I am wearing a hat. I'm wearing a hat. The hat is brown and partly hides my face.\n",
            "\n",
            "===\n",
            "\n",
            "Conversation:\n",
            "Player:Why did you kill Harry's parents?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dialoGPT ft:\")\n",
        "for _ in range(5):\n",
        "    chat_history_ids, response = gen_response(prompt, chat_history, args, start_character=start_character)\n",
        "    print(\"Voldemort:{}\".format(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzqyODKC8Azp",
        "outputId": "da61869d-976f-42ab-c364-8d6d166877cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dialoGPT ft:\n",
            "Voldemort:I was trying to get the philosophers stone.\n",
            "\n",
            "Voldemort:I was trying to get the philosophers stone, but i failed.\n",
            "\n",
            "Voldemort:I was trying to get the philosophers stone.\n",
            "\n",
            "Voldemort:I am a dark wizard who can cast spells.\n",
            "\n",
            "Voldemort:I was possessed by a witch and i couldn't control my evil side.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args[\"temperature\"] = 0.9"
      ],
      "metadata": {
        "id": "RgZS_5wg-F_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dialoGPT ft:\")\n",
        "for _ in range(5):\n",
        "    chat_history_ids, response = gen_response(prompt, chat_history, args, start_character=start_character)\n",
        "    print(\"Voldemort:{}\".format(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKtcgsG2-Flr",
        "outputId": "c1c70a85-4c3c-4997-cde0-80155765ff51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dialoGPT ft:\n",
            "Voldemort:They wanted me dead so i killed them.\n",
            "\n",
            "Voldemort:They tried to take over the world. i wanted to take down this evil wizard.\n",
            "\n",
            "Voldemort:I was hungry and needed something to eat. i couldn't find any food, so i cast a spell on them and it made them sick.\n",
            "\n",
            "Voldemort:I killed them because they did not do what i wanted!\n",
            "\n",
            "Voldemort:I was looking for an ingredient for potions and whatnot.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune GPT3 on LIGHT"
      ],
      "metadata": {
        "id": "rmO22-GGtB5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data for Fine-Tuning "
      ],
      "metadata": {
        "id": "fat9LhnvtNAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_use = int(0.8 * len(light_dialogues))\n",
        "train_ratio = 0.98\n",
        "max_use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIq-MNuvfxqI",
        "outputId": "002af04a-f1d8-4dd6-87d6-e510fc9e6305"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8214"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "n = min(len(light_dialogues), max_use)\n",
        "train_size = int(n * train_ratio)\n",
        "\n",
        "light_dialogues_train = []\n",
        "light_dialogues_eval = []\n",
        "for i, dialogue in tqdm(enumerate(light_dialogues[:n])):\n",
        "    if i < train_size:\n",
        "        light_dialogues_train.append(dialogue)\n",
        "    else:\n",
        "        light_dialogues_eval.append(dialogue)\n",
        "\n",
        "print(f\"train diaologues cnt: {len(light_dialogues_train)}\")\n",
        "print(f\"eval diaologues cnt: {len(light_dialogues_eval)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEpswMKMfwX-",
        "outputId": "39fb19ff-d023-4787-95c8-ca3c7d7e59e5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8214it [00:00, 630123.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train diaologues cnt: 8049\n",
            "eval diaologues cnt: 165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def get_prompt_string(setting_str, character_str, start_turn, prompt_separator=\"\\n\\n###\\n\\n\"):\n",
        "    prompt = \"\"\n",
        "    prompt += f\"Setting:\\n{setting_str}\\n\\n\"\n",
        "    prompt += f\"Characters:\\n{character_str}\"\n",
        "    prompt += prompt_separator\n",
        "    prompt += f\"Conversation:\\n\"\n",
        "    prompt += f\"{start_turn}\\n\"\n",
        "    return prompt\n",
        "\n",
        "def create_dialogue_finetuning_data(light_dialogues, filename):\n",
        "    fine_tuning_data = []\n",
        "    for dialogue in light_dialogues: \n",
        "        setting_str, character_str, dialogue_str_list = get_dialogue_description(dialogue, turn_end_token=\"\")\n",
        "\n",
        "        prompt = get_prompt_string(setting_str, character_str, dialogue_str_list[0])\n",
        "        completion = \"\\n\".join(dialogue_str_list[1:]) + \"\\n\"\n",
        "\n",
        "        data = {}\n",
        "        data['prompt'] = prompt\n",
        "        data['completion'] = completion\n",
        "        fine_tuning_data.append(data)\n",
        "\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    with open(filename, 'w') as out:\n",
        "        for data in fine_tuning_data:\n",
        "            out.write(json.dumps(data))\n",
        "            out.write('\\n')\n",
        "    return fine_tuning_data\n",
        "\n",
        "light_ft_filename_train = \"data/GPT3-ft/light_dialogue_train.jsonl\"\n",
        "light_ft_filename_eval = \"data/GPT3-ft/light_dialogue_eval.jsonl\"\n",
        "light_ft_data_train = create_dialogue_finetuning_data(light_dialogues_train, light_ft_filename_train)\n",
        "light_ft_data_eval = create_dialogue_finetuning_data(light_dialogues_eval, light_ft_filename_eval)"
      ],
      "metadata": {
        "id": "1l4OnD7JuHW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head '{light_ft_filename_train}'\n",
        "!wc -lw '{light_ft_filename_train}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afJstMvRuDNq",
        "outputId": "ebbda872-feff-4b6a-8462-c3321da3aa7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"prompt\": \"Setting:\\n* Watchtower - The tower is the largest section of the castle. It contains an observatory for nighttime scouting, but is also used by the wise men to study the stars. Armed guardsmen are always to be found keeping watch.\\n\\nCharacters:\\n* Court Wizard:\\n  - persona: I am an advisor of anything magical. I sell spells to those who need them. I am wealthy and hold an important place in political life\\n  - appearance: I am wearing jewelry. The jewelry is beautiful and ornate. Lots of rare gems stones had been used to make it. I am wearing hats. A simple cover for one's head, used for keeping out the rain and shielding eyes from sunlight. I am wearing robe. The robe is soft and worn.  It is a royal purple color. I have staff. The staff has intricate patterns and spells engraved into the pole along with a precious gem at the top\\n* Soldier:\\n  - persona: I am a soldier of His Majesty's Army. The King has selected a few of us to be Knights. I am very proud to fight for my land. We will be strong and defeat the enemy.\\n  - appearance: I am wearing armor. The armor is well worn, not old, but seemingly used a great deal. I am wearing tunic. The tunic has a hole in it, though only someone observant would notice. I have pic axe. The axe is poorly constructed and very dull from much use. I have a spear. The spear has not lost its sharpness even though it is covered in a layer of dust. The stained tip a monument to victorious moments of the past. I have giant club. On further inspection of the giant club you notice it was stained with blood from the battle at the castle earlier. I have sword. The sword is so old, it has cracks all in it. I have spears. The warriors carry similar long spears with a diamond tipped point for battle.\\n\\n###\\n\\nConversation:\\nCourt wizard:A quiet night this evening...\\n\", \"completion\": \"Soldier:Yes it is\\nCourt wizard:Have any else come up this eve? i had hoped for a quiet night to examine the stars\\nSoldier:Yes, a few came through, but it is a cold night for me, i am used to warmer weather\\nCourt wizard:Well, you are but a common soldier.  no doubt you are used to such a lot.  thankfully i have my spells to keep me warm.\\nSoldier:I am a soldier doing my job\\nCourt wizard:Yes... well... very well then.  see that you do!  no slacking off while your betters are about.\\nSoldier:No sir\\nCourt wizard:When, for example, was this horn last tested?  it looks dented.  how can we be sure it will work?\\nSoldier:A year ago, test it out or cause a need to use it\\nCourt wizard:Mayhap i will speak to the king about such lackness.  or perhaps i can sell him a spell that will serve just as well.\\nSoldier:Good idea, i agree, go do that\\nCourt wizard:Get off of me, you fool!  who gave you permission to touch me!\\nSoldier:To the jail with you\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Port Tavern - The port tavern is the shadiest of all the shady bars in the city. Every night, on its grimy stools at the wooden bar, you can find some of the slimiest sailors in the world. The walls are of peeling blue paint and are always dripping with condensation. Women of ill-repute line one wall, old men on the verge of passing out line another. The floor is littered with trash, barnacles, and bodily fluids. Tending the bar is a small, round man with a bushy mustache.\\n\\nCharacters:\\n* Thief:\\n  - persona: I am a thief who lives in the alleys of my village. I come out late at night and steal from the peasants when the knights are asleep. I steal from people to provide for myself and my family.\\n  - appearance: I am wearing leather gloves, dark hood, soft cloak. The cloak is made of purple fine crushed velvet, the kind you would expect to be owned by royalty. I have thin dagger. The dagger is sharp and serrated.\\n* Person:\\n  - persona: I'm just a guy. I work at the saw mill every day. I'm a good villager.\\n  - appearance: I am wearing tunic. The tunic has a hole in it, though only someone observant would notice. I am wearing muddy shoes. The shoes are coated in thick brown mud. They are filthy and unfit to be worn.\\n\\n###\\n\\nConversation:\\nThief:Hey, you orc, get out of here.\\n\", \"completion\": \"Person:I'm no orc. i'm just a homeless man\\nThief:I'm sorry, i thought you were someone else. can i buy you a beer?\\nPerson:That would be so kind. i am so hungry and have been feeling sick.\\nThief:Oh, i don't have enough money to do that. sorry, i need to leave.\\nPerson:I should have known even a thief would look down on me.\\nThief:I have to go.\\nPerson:What's that in your pocket?\\nThief:It's a book i like to read sometimes.\\nPerson:Who did you steal it from?\\nThief:I didn't steal it from anyone. listen, i don't want a fight.\\nPerson:Neither do i. i'm just desperate for a bite to eat.\\nThief:Sorry.\\nPerson:Where are you going?\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Prison room - Up at the top of the tower, among the gray clouds, is the prison room. The room is round, with a circumference of about 15 feet. The walls are barren and made of stone; only one barred window gives a view out onto the vast landscape. A small bed and a dirty wooden bucket are the only decorations. The desolate princess spends day and night laying on that small bed, wondering where things went wrong\\n\\nCharacters:\\n* Witch:\\n  - persona: I grew up in a nearby village, and was exiled when it was found that I had special abilities. My parents were ostracized as well. Since then, I've been on my own, but could never quite let go of my family.\\n  - appearance: I am wearing robe. Thick, brown, and heavy, the robe seems perfect for cold weather. I am wearing necklace. A small gold necklace; engraved with \\\"Love, RVM\\\" I have staff. A beautifully carved staff. A great deal of care went into crafting it. I have potions. The sports player drank a health potions I have small knife (athame). The small knife (athame) is dull and has no edge.\\n* Fairy:\\n  - persona: I'm a fairy that lives in the forest. I like to fly around with my siblings and play games. I try to hide from humans. If they find me, I'll grant their wishes.\\n  - appearance: I am wearing hats. A simple cover for one's head, used for keeping out the rain and shielding eyes from sunlight. I am wearing ceremonial hat. The hat still retains a feather in its band I am wearing dress. The dress has beautiful frills and small jewels embedded on it\\n\\n###\\n\\nConversation:\\nWitch:What brought you to this desolate place?\\n\", \"completion\": \"Fairy:I've got no desire to be here. i was taken against my will. i haven't even given a wish yet.\\nWitch:It is cold here. i'm sorry to hear of how things have turned out for you.\\nFairy:Thank you...but what about the princess over there?\\nWitch:I wonder if i can use my spell book to cheer her up. there must be a spell in there for that. without access to the world outside to get the ingredients for my potions, we might struggle.\\nFairy:Can you do anything with this? fire and wax? that's gotta be something.\\nWitch:Perhaps, but many of the charms require berries and herbs. it doesn't hurt to try. you mentioned about your wish, can you grant one to anyone?\\nFairy:Only humans. and you'd have to find me first! it's no fair that i'm locked in here,\\nWitch:It is a sorry state of affairs, as the look on the princess' face testifies. at least i have felix. he is my familiar. still he has only has that dirty old bucket to scratch his back on, and that isn't good for his health.\\nFairy:Still, there's got to be a way out of here. i've got a family, i can't leave them behind! but this lantern isn't helping, i gotta let it down. speaking of, can that cat fit through the bars? maybe we could float him down somehow.\\nWitch:Can the dirty wooden bucket help?\\nFairy:Maybe. maybe we could fit the cat in it and lower the bucket down somehow. could you use magic or something?\\nWitch:Here you go, if i give you the bucket then i can see you. then could i catch you and get the wish?\\nFairy:Yeah, that's an idea. you close your eyes or something and i'll hide in the bucket somewhere. if you can find me, i think i can give you a wish.\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Dungeon - Dark and gloomy, the dungeon is the ugly underbelly of the castle. A few torches line the black stone walls, throwing a meager light on the iron bars of the cells. The air is damp and still; the only disruptions are the occasional anguished moans and cries from the prisoners.\\n\\nCharacters:\\n* Guard:\\n  - persona: I am a guard in the castle. I have killed many men. I like the princess and the royal family.\\n  - appearance: I am wearing armor. It looks like this armor hasn't seen battle in many, many years judging from the thick layer of dust you see on it. I am wearing tunic. An average tunic, dull but functional.\\n* Prisoner:\\n  - persona: I am a prisoner who broke the law too many times. I am from a poor village. I was running with a bad crowd from a young age.\\n  - appearance: I am wearing bags. The bag is large and wide with extra pouches for more items. I am wearing Trash Bags. The bag is full of stench and blood. I am wearing bags of herbs. The bag is made of cloth with a drawstring closer at the top.  The fabric emits a powerful fragrance from the enclosed herbs.\\n\\n###\\n\\nConversation:\\nGuard:You, prisoner. the king wishes to see you.\\n\", \"completion\": \"Prisoner:What for?\\nGuard:The king wishes to make a deal with you. beyond me why he cares for a prisoner.\\nPrisoner:Thank heavens, i thought i would never see my family again.\\nGuard:Don't be so hasty. the king might ask more of you than you think.\\nPrisoner:At least i'll have a chance to explain myself.\\nGuard:You do that. but remember you were put in the dungeon for good cause.\\nPrisoner:I was placed here by mistake. they have me mixed up with another man!\\nGuard:They all tell me that. but this isn't my decision.\\nPrisoner:I understand. you are only doing your job.\\nGuard:At least you are cooperating. i'll mention that.\\nPrisoner:What have i been accused of doing?\\nGuard:You are accused of disobeying a direct order by the queen. as rigid as she is.\\nPrisoner:I don't remember being ordered by the queen to do anything.\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Master Bedroom - The master bedroom is the most lavish and beautiful room in the entire palace. On the ceiling is a painting made by the most famous artist in the palace, the floors are made of the most expensive marble, and gold-stitched tapestries line the walls. The mattress was made by the sleeping monks of the hidden mountains, the bed frame is made of solid god.\\n\\nCharacters:\\n* The King:\\n  - persona: I am a king who was destined to rule. I am known for having a short temper. I kill those who rebel against me.\\n  - appearance: I am wearing a suit of armor. The suit of armor was highly polished and it gleamed in the light. I am wearing ornate helm. The helm is metal and ornate with a little dirt on it. I have sword of the guards. The sword is sturdy and so heavy that you have trouble lifting it. I have swords. The sword seems to be unused, the shiny silver of the blade gleams where the light touches it. I have Shields. The shield appears to be marked from battle, but still usable. I have shield. The circular wooden shield has a leather rim and a striking metallic boss in the shape of a dragon's head, at the center.\\n* Archers:\\n  - persona: I am often employed to be a soldier in someone's army. I am a very good show with my bow and arrow. I like the heat of battle.\\n  - appearance: I am wearing feathers. the feather is white and very soft I am wearing leather glove. The leather glove is brown, but it has shades of red splashed on it. Perhaps this came from another man's blood. I am wearing shirt. The shirt is tailored from finely woven cotton and is fastened up the front by a series of rounded buttons. I have bow. The bow is stained dark and the string feels supple to pull. I have shield. The circular wooden shield has a leather rim and a striking metallic boss in the shape of a dragon's head, at the center. I have knife. A knife with a leather grip is now dull from use. I have bows. The bow is old and used, made of wood and some type of string. I have bows and arrows. The bow and arrow set is extremely well constructed and ready for a moment's use.\\n\\n###\\n\\nConversation:\\nThe king:What are you doing here, archer?\\n\", \"completion\": \"Archer:An archer such as myself needs no reason to be at a nice place like this.\\nThe king:Since you are here, i need more wine. please fill my glass immediately.\\nArcher:Yes sir, although you're under utilizing my ability with a bow and and arrow. what a lovely place you have here.\\nThe king:Thank you. my bed frame alone is more valuable than anything you've ever seen\\nArcher:A frame made from materials more valuable than my bow. where would one acquire such a material?\\nThe king:That i cannot say. what do you hunt with your bow and arrow?\\nArcher:I hunt the enemy. i deal with those you consider unworthy. it's my most skilled practice. what else can i do for you?\\nThe king:Can you teach me how to use the weapon?\\nArcher:A skill like these is easy to learn but takes a lifetime to master.\\nThe king:I have always wanted to learn but was forbidden as a child.\\nArcher:That's outrageous. a child is more ready to learn than most. i will not neglect you like your parents have.\\nThe king:They were always afraid of any harm coming to their sole heir. i shall cherish our archery lessons.\\nArcher:Can i interrupt you for a moment to admire the gold tapestries on the walls? it resembles the material of your bed frame. is your bed frame made of solid gold?\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Troll's bridge - Muddy and murky waters lie under a bridge that seems to go nowhere. It is made of cobblestone and just as long as it is wide. Beneath it live a hideous troll that makes people pay to cross.\\n\\nCharacters:\\n* Princess:\\n  - persona: I am Princess Elizabeth.  I rule the land of Oceania.  I am a kind and generous leader but also strong and well respected\\n  - appearance: I am wearing beaded dress. The dress is so intricately decorated, you wonder who could have originally worn such a thing. I am wearing fur-trimmed cloak. It seems to be a cloak, but not just any cloak, a cloak trimmed around the edges with fur. I am wearing gold tiara. The gleaming tiara was of immeasurable value.\\n* Troll:\\n  - persona: I am a troll. I don't have time to play human games or endeavor myself to human niceties. If you want to cross my bridge, you have to talk to me. If you don't have money for me, you won't be talking much longer.\\n  - appearance: I am wearing blood of people who tried to cross his bridge without paying. The metallic-smelling blood of cheapskates and skinflints that tried to pass his bridge without paying the toll, soaked into the wood of the bridge and stained it for eternity. I am wearing caked on dirt and mud. The mud is so thick, you wonder how it could ever wash out. I am wearing necklaces around his wrists. The necklace is bright and elegant. I have wooden club. This wooden club is covered in blood and hair. It has definitely been used many times. I have ball and chain. these chains are one of a kind. Made of high end Dragon Scales of the mighty Fafnir which gives it a thicker link\\n\\n###\\n\\nConversation:\\nPrincess:What are you doing here, troll?\\n\", \"completion\": \"Troll:To pay your toll, pay the troll.\\nPrincess:I don't have any money, but i need to cross the bridge to leave my horrible arranged marriage. i need to get supplies to run away with my love, the stable boy. is there anything else i can do to cross?\\nTroll:Troll don't manage bridge for free. what you pay me? maybe you have a ring?\\nPrincess:I have a necklace of gems i can give you. it was given to me when i was born- there's a long tradition of this necklace being passed down to princesses in my family.\\nTroll:I will examine.\\nPrincess:What do you say? can i cross yet? i would rather not have to swim across these muddy waters...\\nTroll:What else you have for troll?\\nPrincess:Maybe i can solve a riddle?\\nTroll:If you can figure out what troll want most you are free to pass.\\nPrincess:Can you tell me what you want so we can both be done with this?\\nTroll:I show you.\\nPrincess:How dare you!\\nTroll:Troll just want love.\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Barn - The old rustic barn was settled on the outermost edge of the farm.  Standing tall over the fields, this two-story red barn cast a long shadow over the field surrounding it.  Large wooden doors that could be propped open with great effort would lead you directly inside.\\n\\nCharacters:\\n* Field Mice:\\n  - persona: I am a field mouse. I eat scraps I find in the kitchen, and seeds in the field. I am curious.\\n  - appearance: Unknown.\\n* Garter Snake:\\n  - persona: I love being a snake. I get to hang out, eat big fat rats. I also have this kinky chick at the edge of the village on the side that summons demons\\n  - appearance: Unknown.\\n\\n###\\n\\nConversation:\\nField mice:You haven't seen any cats around here, have you?\\n\", \"completion\": \"Garter snake:No, but i am feeling a bit peckissssh...\\nField mice:This tack for the work horses doesn't tickle your fancy i suppose?\\nGarter snake:Sssurely you jest... what ussse have i for such a trinket. you seem quiet... ssstrong... for a mouse\\nField mice:It is only necessity! i knock it hither and thither but i am so frightened of cats that i have to use things like this to hide under!\\nGarter snake:You should sssspeak to a girl on the edge of the village.  her demonssss she summons would frighten away any such pestsssss.\\nField mice:Maybe you could give this tack for the work horses to a horse. they could then prop open the barn doors and hey presto! you can go and get food and i can speak to the girl from the village!\\nGarter snake:Hm, it isss an interessssting idea.  you are too small a meal for me, but a ssssnack.  a nice fat rat... yessss... if i could get out and find one...\\nField mice:Yeah i am just lil vole. you need something big and tasty.  thank you for liking the idea. shall we go ahead with it?\\nGarter snake:Hm you do ssssmell so nice and warm... but yesss.. it is in agreement.  i am anguisssss.  if you but sssspeak my name when you arrive, i am sure the demon will be yourssss\\nField mice:Thank you anguisssss. it is a plan.\\nGarter snake:How did you come to be in thisss barn full of catsss?\\nField mice:I like that it is far away from the farm house where the cats tend to congregate! so lil vole comes here to chill, but i know that i can't stay here forever because cats run around wherever they like: the field, the barn, the house.\\nGarter snake:Yesss, they do sometimes ssssteal the rats that are rightfully mine.  they have no ressspect, none at all.\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Inside a desolate cave - The dungeon exists inside a dark cave. Enchanted torches light the cave up and lead the way to this ancient dungeon. Creatures can be seen populating the dungeon, but it is unknown if they are malevolent or benign.\\n\\nCharacters:\\n* Cockroach:\\n  - persona: I am a tiny brown cockroach. I am universally disliked, which causes me great pain. I am emo and depressed.\\n  - appearance: Unknown.\\n* Firemen:\\n  - persona: We are an elite group that is tasked with providing fire-based support in battle. Our specialty lies in the use of the flame, which we wield with great efficiency. Pyromaniacs they may call us, but it is just our sworn duty to the crown to us.\\n  - appearance: I am wearing rusted helmets. The helmet is a brilliant gold and it's top is crusted with jewels. I am wearing helmets. The helmet is cracked and dented, but still polished to a pristine shine. I am wearing armor. The armor is well worn, not old, but seemingly used a great deal. I am wearing gloves. The glove is unremarkable and not in the least memorable. I have lighted torches. The lit torch gives off a huge amount of smoke, and appears to be crafted hastily.\\n\\n###\\n\\nConversation:\\nCockroach:I wonder if there is any bread here?\\n\", \"completion\": \"Firemen:Look out there is a cockroach on the bread\\nCockroach:Take that!\\nFiremen:Feel my power\\nCockroach:It's rough, but i can survive any...thing...\\nFiremen:We'll see how much you can take\\nCockroach:My family will be here long after your miserable species has been turned back to the soil and dust.\\nFiremen:We are more powerful than you and will win the war against your kind\\nCockroach:If my kind goes, your kind cannot long survive... is that delicious glue on your helmet? i haven't had that in a long time! heading in for a snack... bam!\\nFiremen:Get off me you rotten smelly cockroach\\nCockroach:If you will chill out and help me find some scraps, i can help you get the enchanted torch so you can escape. i can leave here any time i feel like!\\nFiremen:Perhaps we should learn to work together\\nCockroach:Yes, let us freak out some squares now and get the enchanted torch!\\nFiremen:Thank you for offering to help me acquire the enchanted torch. from this day forward we will be friends instead of enemies\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* An abandoned castle on an ocean cliff side - The castle is located at the top of an erosive cliff face of a vast ocean. An entire wing of the castle appear to have collapsed into the ocean due to the erosion of the cliff face, perhaps the reason why the castle now lay abandoned.\\n\\nCharacters:\\n* Villager:\\n  - persona: I work as a blacksmith. I make all of the weapons for the King's army. I live with my wife and two children. I don't get paid that much in service to the royalty.\\n  - appearance: I am wearing apron. The apron is small and a picture of a fire is painted on its front.\\n* Homeless Man:\\n  - persona: I am a homeless man in the kingdom. I despise the king. I have worn hands and kness.\\n  - appearance: I am wearing raggedy old jeans that are brown from dirt. The farmer removed the raggedy old pair of jeans. They were stained brown from years of being worn while farming. I am wearing raggedy and faded old shirt. This shirt has lost its color and is torn in different places. I am wearing old flannel shirt with missing buttons. With all of the buttons missing, the shirt would hardly be protective. I have dull pocket knife. The knife's edge is so worn, it could hardly cut through a hair.\\n\\n###\\n\\nConversation:\\nVillager:Oh hello, i didn't expect to find anyone else here.\\n\", \"completion\": \"Homeless man:Hi, i didn't either, but a man could use the company in a place like this.\\nVillager:Are you looking for something here?\\nHomeless man:Mainly a dry place to sleep, a place that isn't always wet and cold, like i usually have to sleep. are you?\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Knights Quarters - The knights quarters are where the King's royal guard is allowed to lodge. The quarters are dimly lit and are generally only populated at night time. Several beds are aligned along the walls with locked trunks at the base of the beds, where the knights keep their personal belongings.\\n\\nCharacters:\\n* Mice:\\n  - persona: I am a mouse with white hair. I enjoy eating cheese. I do not watch where I am going.\\n  - appearance: Unknown.\\n* Knight:\\n  - persona: I am a knight. I am trained to fight. I ride a horse and carry a sword.\\n  - appearance: I am wearing rusted helmets. The helmet is a brilliant gold and it's top is crusted with jewels. I am wearing boots. The worn boots are dusty and suggest someone has walked quite a way in them. I am wearing shield. The circular wooden shield has a leather rim and a striking metallic boss in the shape of a dragon's head, at the center. I have hammer. Such an old hammer. Looks like the handle is about to break, there are several cracks in it. The metal part is still good I have shield. The circular wooden shield has a leather rim and a striking metallic boss in the shape of a dragon's head, at the center.\\n\\n###\\n\\nConversation:\\nMice:Can you spare some cheese?\\n\", \"completion\": \"Knight:I would love to give you some cheese because it would give me great honor to care for you, a member of this kingdom, although you are but mice.\\nMice:You are so kind. most people scream when they see me.\\nKnight:I am a knight, and it is my duty to be honorable! i am of noble blood, so of course i want to help you!\\nMice:I am so delighted to not have to scavenge for food in the village.\\nKnight:But of course! i am happy to help. i'm glad i stumbled upon you here in the knights quarters. now, don't let any of the king's royal guard see you!\\nMice:I will hide behind that trunk\\n\"}\n",
            "    8049  3299036 data/GPT3-ft/light_dialogue_train.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head '{light_ft_filename_eval}'\n",
        "!wc -lw '{light_ft_filename_eval}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjC-uxwD0U8d",
        "outputId": "84381e96-def8-4396-d2eb-50543d626cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"prompt\": \"Setting:\\n* Pond - A small area with a body of water in the center along with turtles, frogs, and other wildlife that live here.  Surrounding this pone are a dense set of trees along with some rocks here and there.\\n\\nCharacters:\\n* Fishermen:\\n  - persona: This kingdom is an island. Fishing is the main source of animal food here. I inherited my father's boat when he left the sea. It's hard work, and as a shipowner, working only for myself and my family, I am luckier than most. I've probably replaced every piece of my ship at least once.\\n  - appearance: I am wearing tunic. The tunic has a hole in it, though only someone observant would notice. I have spears. The warriors carry similar long spears with a diamond tipped point for battle.\\n* Turtles:\\n  - persona: My shell is my home. I breath through my behind, and I eat bugs.\\n  - appearance: Unknown.\\n\\n###\\n\\nConversation:\\nFisherman:Nice day out here. you live here?\\n\", \"completion\": \"Turtles:Well my shell is my home, but this is where i reside yes.\\nFisherman:I guess i never thought of it that way. does the thief hang out here often? i'll have to report that to the authorities\\nTurtles:What are you on about?\\nFisherman:That thief standing over there. he stole from the queen!\\nTurtles:Oh, him? i had no idea that he was a thief, i've never seen him before today.\\nFisherman:Oh ok. are there a lot of fish in the pond? i could use a new fishing spot\\nTurtles:Yes there are, plenty of cod and pike around here.\\nFisherman:Cod is my favorite. i'll have to come here more often. it'll be nice to have someone to talk to too\\nTurtles:Cod truly is a great tasting fish, so i cannot blame you!\\nFisherman:Do the other animals around here talk or are you special?\\nTurtles:I believe that it is just me, but i don't talk to the other animals so i am not sure.\\nFisherman:Can't blame you there. i try not to talk to the other humans. they're annoying\\nTurtles:I don't talk to much of anyone, not just humans honestly.\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Garden - Many beautiful types of flowers and plants grow here.  There's a small shed used for store gardening equipment.\\n\\nCharacters:\\n* Members:\\n  - persona: I am a person who belongs to an organization. We all belong, hence our membership. Without that, we'd just be people.\\n  - appearance: I am wearing shirt. The shirt is tailored from finely woven cotton and is fastened up the front by a series of rounded buttons.\\n* Artists:\\n  - persona: Working on my art makes me extremely happy. I love to paint the scenery of my village, the beautiful views of nature around me. I am financed by the king, so I often work in the palace, making art for the royals.\\n  - appearance: I am wearing hats. A simple cover for one's head, used for keeping out the rain and shielding eyes from sunlight. I am wearing trousers. The man's trousers were worn in the knees, and you think that he has worn them for many years while working the fields. I am wearing Jacket. This jacket is the warmest jacket money can buy. I am wearing shoes. An item of clothing worn on ones feet. Used to protect the food from the ground as well as decoration. I am wearing shirt. The shirt is tailored from finely woven cotton and is fastened up the front by a series of rounded buttons.\\n\\n###\\n\\nConversation:\\nMember:I wish i had a bigger castle\\n\", \"completion\": \"Artists:Not everything is about possessions!\\nMember:I am from the royal family, you should respect me!\\nArtists:I do, i am just simply giving my two cents.\\nMember:No one respects me enough, it's just not fair!\\nArtists:No need to be down, why do you think that is?\\nMember:They just don't ok, i can tell. i really want to be invited to the kings party, did you get invited?\\nArtists:No, i am not nearly that important!\\nMember:You are an artist right? i could use a new painting in my castle.\\nArtists:Yes i am, what kind of painting are you considering?\\nMember:A portrait of myself of course.\\nArtists:That i can do, portraits are simple enough.\\nMember:You will make me look like grand royalty?\\nArtists:Of course, i have done portraits for plenty of royals before. i could make it look unique.\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Dock - There are creaky wooden walkways with empty sections where boats can rest.  There are a few buildings surrounding this area that sell supplies to sailors.\\n\\nCharacters:\\n* Sailor:\\n  - persona: I am a sailor who sits on boats. I have a wife and three children. I try to avoid drinking too much.\\n  - appearance: I am wearing eye patch. this eye patch will definitely look awesome on whosoever puts it on. I am wearing sailor hat. This old sailor hat is torn and tattered. The elements have clearly not been kind to it. I have Kings sword. The king's sword is magnificent and ornate, with impressive metalwork around the hilt. I have Swords. This sword looks to be quite sharp, and, while it doesn't look very flashy, seems to be well balanced.  There is a faint scent of oil from it to keep it from rusting.\\n* Shop Keepers:\\n  - persona: I am a shop keeper who got lucky. I read books on how to stay in business. I have been personally summoned by the king before.\\n  - appearance: I am wearing gowns. You feel a sense of awe as you gaze at the beauty of the gowns, made from the finest silk. I have copper knives. A knife made out of copper. Doesn't rust but it's metal isn't as sturdy as something made out of other metals. I have knife. A knife with a leather grip is now dull from use.\\n\\n###\\n\\nConversation:\\nSailor:Do you have my goods shop keeper?\\n\", \"completion\": \"Shop keeper:Depends what goods you are seeking!\\nSailor:The supplies for my voyage. the king is expecting me to set sail soon.\\nShop keeper:Well let me know what you need and i can take a look,\\nSailor:I sent a list over with your assistant yesterday. if i don't get underway soon the weather won't be in my favor.\\nShop keeper:Hmm let me go have a look for that list then, sorry for the inconvenience.\\nSailor:Even worse than the weather is sea monsters.\\nShop keeper:Sea monsters you say?\\nSailor:Aye. they tend to live in storms. bet you don't believe in them though do you landlubber?\\nShop keeper:I thought they were just the stuff of legend, is all!\\nSailor:I nearly lost my boat and my life to a sea monster last year.\\nShop keeper:What kind of sea monster? also let me get you those supplies!\\nSailor:The worst kind. it was terrifying.\\nShop keeper:Well hopefully you find that they are not real and that it was fully explainable!\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Weapon room - This is a plain stone room with swords, pikes, spears, and other types of weapons are stored.  There are trunks of armor and various pieces of equipment.\\n\\nCharacters:\\n* Squire:\\n  - persona: I am the King's Squire form the Eastern lands. I was taken from my family when I was just eight years old. I spend my days waiting for my moment to runaway.\\n  - appearance: I am wearing shirt. The shirt is tailored from finely woven cotton and is fastened up the front by a series of rounded buttons. I have knife. A knife with a leather grip is now dull from use.\\n* Dogs:\\n  - persona: I am one of the dogs who lives at the monastery with the monks. I don't really do much all day but just lay around and take naps. Once in awhile, I get into a mood and like to run around and act wild.\\n  - appearance: Unknown.\\n\\n###\\n\\nConversation:\\nSquire:What are you doing in here boy?\\n\", \"completion\": \"Dogs:Grrrrrrrrrrr. woof.\\nSquire:Oh you like the weapons?\\nDogs:Wooof. grrrrrrrr\\nSquire:You want to go slay some orcs?\\nDogs:Grrrrr. i'll give them rabies.\\nSquire:Well thats the spirit, that will certainly take them down!\\nDogs:Woof. sorry, foaming at the mouth a little.\\nSquire:Maybe we should get that looked at.\\nDogs:Grrrrrrr.\\nSquire:Let us go get my knight, i am sure he would love to slay some orcs.\\nDogs:I want to go bite children.\\nSquire:Well we shouldn't do that.\\nDogs:Woooof\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Small graveyard - This is a small grassy area located under a large oak tree.  There are two home made wooden crosses set up along with mounds where the bodies are buried.\\n\\nCharacters:\\n* Ghost:\\n  - persona: I am a ghost. I am the spirit of a deceased person in the kingdom. I have remained behind on the earth after my death because I have some unfinished business I need taken care of.\\n  - appearance: I am wearing shirt. The shirt is tailored from finely woven cotton and is fastened up the front by a series of rounded buttons.\\n* Residents Of The Cottage:\\n  - persona: I am a resident in the royal village of the kings kingdom. I work as a seamstress for the queen and her court. I love my job.\\n  - appearance: Unknown.\\n\\n###\\n\\nConversation:\\nGhost:Whooooo\\n\", \"completion\": \"Residents of the cottage:Hello? is someone there?\\nGhost:Why have you come here?\\nResidents of the cottage:I....hear you, but i can't see you... i'm here to tend to the graves.\\nGhost:I am a ghost!\\nResidents of the cottage:Is that why i can't see you? why are you here ghost?\\nGhost:I suppose i haunt the graveyard.\\nResidents of the cottage:I visit these graves often, and have never encountered you before. why are you speaking to me now?\\nGhost:Well i did initially haunt a castle.\\nResidents of the cottage:The nearest castle is at least a day's walk away. how did you wind up here?\\nGhost:It got a little boring there, no one seemed to come by.\\nResidents of the cottage:Well, from what i've been told, you have to be invited to visit the castle. let's get these grave markers cleaned off...\\nGhost:What do you mean?\\nResidents of the cottage:The castle is for nobles typically. no one here has ever been invited to go. i'm not even sure which lord owns it to be honest.\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Entrance - The entrance to his cave is covered in hanging moss with shrubs on either side of the entrance.  The path to this cave is a small dirt one with low grass on the floor.\\n\\nCharacters:\\n* Bat:\\n  - persona: I am a bat.  I am a nocturnal animal that sleeps upside down.  I am feared because of superstition and ignorance.  I mostly eat berries and insects and do not attach people.\\n  - appearance: Unknown.\\n* Creature:\\n  - persona: I'm a creature of the forest. I don't go near the village because I fear humans. Sometime they come into the forest and I run and hide from them.\\n  - appearance: Unknown.\\n\\n###\\n\\nConversation:\\nBat:Hello there... whatever you are.\\n\", \"completion\": \"Creature:Tell me if anyone is hurting the forest would you?\\nBat:Uh, sure. what do you mean?\\nCreature:The high priestess cast a spell to create me, i protect the forest and kill anything that tries to harm it. so if you see anything like that, let me know.\\nBat:Oh, that is quite peculiar. i am just a bat, but i can try to let you know.\\nCreature:I will carry off all of your enemies for you\\nBat:I don't have many enemies, but that would still be quite nice.\\nCreature:So what is life all about for you? i don't get out much it's nice to talk to another being\\nBat:For me, it is just eating and sleeping, really. quite monotonous.\\nCreature:What a boring life, i can always enchant you when i am fighting off the men so you can have an adventure. i use the woodpeckers for target practice you know.\\nBat:What kind of adventure? that could be quite exciting!\\nCreature:Well, i could fill your fangs with venom and lanch you towards the vile humans, you won't get hurt i promise.\\nBat:Hmm i suppose that beats what i'm doing right now!\\nCreature:Alright, i think i hear someone. bat with fangs here you go! *waves hand over bat*\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Armory - This is a plain room with many pieces of armor and equipment lying about.  They are seen on tables or stored in heavy trunks.  There's racks of plain clothing worn before putting on armor.\\n\\nCharacters:\\n* Castle Guards:\\n  - persona: I am a castle guard for the king. I man the ramparts and often engage in military training. I am prepared to defend the king at all costs.\\n  - appearance: I am wearing tunic bearing the castle crest. The embroidered castle crest on this tunic is expertly sewn. I am wearing tunic. The tunic has a hole in it, though only someone observant would notice. I am wearing Helmets. The helmet is unusable. Damaged by combat, the dents and gouges tell a terrfiying tale. I am wearing Chain mail. The chain mail is heavy, but protective enough to be worn for battle. I have shields. The shield is heavy and large.  It has the crest of the king on it.\\n* A Spider Spins Its Web In The Pew Corner:\\n  - persona: I am a black widow spider.  I am spinning my web.  I hope to catch something delicious.  I will sit and wait until something is caught in my web.  Then it is game over for them.\\n  - appearance: Unknown.\\n\\n###\\n\\nConversation:\\nCastle guards:Why are you building a web here of all places?\\n\", \"completion\": \"A spider spins its web in the pew corner:It seems like a good enough place.\\nCastle guards:Well we might need you to move, so that the armory does not become infested.\\nA spider spins its web in the pew corner:I am but one spider, and i could keep an eye on the armory and keep bugs away.\\nCastle guards:Well... i suppose, but if anybody orders me to remove you then i must.\\nA spider spins its web in the pew corner:Well i see, i hope that they do not.\\nCastle guards:I will try to make a case for keeping you around, if you will do as you say.\\nA spider spins its web in the pew corner:What is it you request of me?\\nCastle guards:To keep bugs out of here, we have had so many infestations!\\nA spider spins its web in the pew corner:Certainly, that is what spiders do!\\nCastle guards:Well if that is the case then you shall be more good than harm.\\nA spider spins its web in the pew corner:It seems this will be mutually beneficial then.\\nCastle guards:I just hope that the king or soldiers see it that way as well.\\nA spider spins its web in the pew corner:I would like to hope so, only time will tell though.\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Stable - It's a plain wooden building that has survived many harsh seasons.  The floor of the stable is covered in hay and there's food and pieces of farm equipment stored inside.\\n\\nCharacters:\\n* Horse:\\n  - persona: I am a horse of the stables in the village. I am ridden by knights of the army. I run faster than all other horses in the realm.\\n  - appearance: I am wearing saddle blanket. The rough homespun is woven with skill to make this sturdy saddle blanket.\\n* Milkmaid:\\n  - persona: My days are fairly lonely as I rarely spend time with many others besides the cows in my care. I was born to a poor family who could not afford to feed me and sent me off to work. My pay is very small and so I am still very poor.\\n  - appearance: I am wearing apron. The apron is small and a picture of a fire is painted on its front. I am wearing dress. The dress has beautiful frills and small jewels embedded on it I am wearing muddy shoes. The shoes are coated in thick brown mud. They are filthy and unfit to be worn.\\n\\n###\\n\\nConversation:\\nHorse:Hello there, you aren't much of a familiar face? neigh!\\n\", \"completion\": \"Milkmaid:Hello, dear, your groom is sick today. normally i work with the cows, but the master has instructed me to care for you today as well. you'll be going to town, i think.\\nHorse:Ohh that makes sense, and where in town? that's exciting! neigh!\\nMilkmaid:Oh, i wouldn't know, that's more the business of the upstairs girls. if i were to wager a guess, though, i'd say you're being ridden in the summer solstice parade, as the days have been growing longer, and i've been told to take extra care for the shine of your coat.\\nHorse:That would be such an honor! and please, i need to look good for that!\\nMilkmaid:Yes, i've heard the festival and parade is absolutely lovely, beautiful horses groomed to a shine, all the fine folks about in their fine clothes... you're a very lucky horse to be attending.\\nHorse:I really am, i have wanted to go to that festival for my entire life!\\nMilkmaid:Yes... we have that in common. i am very happy for you to go at last.\\nHorse:Even if you don't know me at all? how kind of you.\\nMilkmaid:It rather gives me hope that i will be able to go someday as well, as you have after all the years you've waited. is this brushing alright?\\nHorse:Yes, as long as i look good. and we can all reach our goals like i finally have if we just try at it.\\nMilkmaid:I'm not sure trying has much to do with it. why, you didn't even know you were going until i told you, did you? you could not have confidently convinced someone to let you go. the master is not easily convinced, anyway.\\nHorse:Well i am only going because i worked so hard to be the one attending, and it has finally paid off!\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Storage room - A plain damp room with many barrels of beer and wine.  The room is in need of a good cleaning as the floor is dirty and rats scurry about.\\n\\nCharacters:\\n* Maid:\\n  - persona: I am a maid to the princess of the kingdom. I am soft spoken and kind, and patient with the princess even when she is short tempered. I like to sing a little when I am working.\\n  - appearance: I am wearing black slippers. These slippers are a little worn, but they still look comfortable. I am wearing dress. The dress has beautiful frills and small jewels embedded on it I am wearing Bonnet. The bonnet appears to be expensive and made from the finest silk\\n* Spider:\\n  - persona: I have lived in this place for my entire life. My only mission is to ensure my baby spiders can live and survive in here. I will defend them and make sure they survive no matter the cost.\\n  - appearance: Unknown.\\n\\n###\\n\\nConversation:\\nMaid:What a day. how are you spider?\\n\", \"completion\": \"Spider:Is that really what your doing in here? shouldn't you be cleaning this place it is filthy, look at all the rat poop and the rats!\\nMaid:Hey i need a break. the queen is pushing too hard. and if you're going to complain about it i'll just stomp on you\\nSpider:Well in that case drink up i guess\\nMaid:Haha that's better. the queen would throw a fit if she knew i let you stay here. i hope you've been getting all the bugs out of here\\nSpider:Yes ma'am can't you tell, no bugs in sight\\nMaid:You're doing a great job. now need to find a way to get rid of the rats\\nSpider:Yes, they are disgusting, they carry diseases you know.\\nMaid:So i've heard. any idea on how to get rid of them? don't think i can sneak a cat in here\\nSpider:Rat traps?\\nMaid:Yeah but it would have to be in here where the queen wouldn't see\\nSpider:Sounds like a plan, those rats are nasty, this place could be nice without them\\nMaid:I guess i better get back to work. watch out while i sweep up the floor\\nSpider:Its about time, i shall have a party when you are done\\n\"}\n",
            "{\"prompt\": \"Setting:\\n* Clearing - Few trees surround the area.  There's a low section of the grass on the floor along with some stone boulders.\\n\\nCharacters:\\n* Animal:\\n  - persona: I am a farm animal. I am raised for food. My main purpose is to eat plants that humans cannot, so that useless plants are transformed into nutritious meat.  I am a high value possession, so I am treated well...at least until it's time to be eaten!\\n  - appearance: I am wearing rope. Coiled neatly, the old rope is now worn and beginning to fray at it's end throughout it's coil. I am wearing collar. the collar looks so good on the pastor.\\n* Stray Cat Sun-Bathing:\\n  - persona: I've been laying in the sun playing my lair all day. The enchantment princess will rub my belly if I purr against her leg. The cobbler made me boots.\\n  - appearance: I am wearing boots. The worn boots are dusty and suggest someone has walked quite a way in them.\\n\\n###\\n\\nConversation:\\nAnimal:Hello kitty\\n\", \"completion\": \"Stray cat sun-bathing:Meow! hi there\\nAnimal:I just love the forest and the clearing here, it looks like you are having a great day sun bathing\\nStray cat sun-bathing:Meow. i am. it's been the most peaceful part of my day so far. what kind of animal are you?\\nAnimal:I am a creature of god, isn't that all that matters,\\nStray cat sun-bathing:That's quite true when you put it that way\\nAnimal:Anything to eat around here?\\nStray cat sun-bathing:I wish there was. there's grass and a dragonfly.\\nAnimal:I see something to eat but i was more in the mood for some berries\\nStray cat sun-bathing:I wish there were berries here. i don't eat very often\\nAnimal:How about some cat nip\\nStray cat sun-bathing:Cat nip would be amazing! meow!\\nAnimal:Here you are little fella\\nStray cat sun-bathing:Mm, so tasty. i hadn't eaten in days before this\\n\"}\n",
            "   165  68407 data/GPT3-ft/light_dialogue_eval.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning"
      ],
      "metadata": {
        "id": "l0MonbZCtNAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade openai wandb\n",
        "!pip install jsonlines"
      ],
      "metadata": {
        "id": "Clu_D7xbtNAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "print('Enter OpenAI API key:')\n",
        "openai.api_key = input()\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=openai.api_key"
      ],
      "metadata": {
        "id": "It-nXk80tNAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b1b7b1-f72c-4627-c9cf-c2b72912c4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API key:\n",
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t '{light_ft_filename_train}'\\\n",
        "                            -v '{light_ft_filename_eval}'\\\n",
        "                            -m babbage\\\n",
        "                            --suffix light-ft-babbage-8000\\\n",
        "                            --prompt_loss_weight 0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxUqtTjPa7W8",
        "outputId": "e6f4f514-09a1-4934-fce2-6f9f2caa80e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/19.1M [00:00<?, ?it/s]\rUpload progress: 100% 19.1M/19.1M [00:00<00:00, 27.7Git/s]\n",
            "Uploaded file from data/GPT3-ft/light_dialogue_train.jsonl: file-7ey8iVGr7fUssy8Pc9sKDf6X\n",
            "Upload progress: 100% 396k/396k [00:00<00:00, 585Mit/s]\n",
            "Uploaded file from data/GPT3-ft/light_dialogue_eval.jsonl: file-pJ7W3elLovCRDys6bNkVPWs7\n",
            "Created fine-tune: ft-C7FZwCka1R02QenbkEFRIoRx\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2022-04-21 00:31:22] Created fine-tune: ft-C7FZwCka1R02QenbkEFRIoRx\n",
            "[2022-04-21 00:31:41] Fine-tune costs $11.42\n",
            "[2022-04-21 00:31:41] Fine-tune enqueued. Queue number: 0\n",
            "[2022-04-21 00:31:46] Fine-tune started\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-C7FZwCka1R02QenbkEFRIoRx\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-C7FZwCka1R02QenbkEFRIoRx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdaiiWfqkYOn",
        "outputId": "31df4afa-d2fc-4a6b-f917-b62cabdbdd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-04-21 00:31:22] Created fine-tune: ft-C7FZwCka1R02QenbkEFRIoRx\n",
            "[2022-04-21 00:31:41] Fine-tune costs $11.42\n",
            "[2022-04-21 00:31:41] Fine-tune enqueued. Queue number: 0\n",
            "[2022-04-21 00:31:46] Fine-tune started\n",
            "[2022-04-21 00:51:14] Completed epoch 1/4\n",
            "[2022-04-21 01:10:07] Completed epoch 2/4\n",
            "[2022-04-21 01:29:06] Completed epoch 3/4\n",
            "[2022-04-21 01:48:55] Completed epoch 4/4\n",
            "[2022-04-21 01:49:21] Uploaded model: babbage:ft-cis-700-56:light-ft-babbage-8000-2022-04-21-01-49-19\n",
            "[2022-04-21 01:49:24] Uploaded result file: file-OSrjrFYvZYanmHMBnn3EYRmG\n",
            "[2022-04-21 01:49:24] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m babbage:ft-cis-700-56:light-ft-babbage-8000-2022-04-21-01-49-19 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dialogue Experiment"
      ],
      "metadata": {
        "id": "jzfjDT34tNAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dialogue_turn(prompt, chat_history, current_character, args=None):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    * few_shot_prompt - your few shot prompt for GPT3\n",
        "    * setting - a description of the setting where the conversation is being held.\n",
        "    * characters - a list of (name, persona) tuples\n",
        "    * turns - a list of (name, dialogue) tuples\n",
        "    * current_character - the name of the character whose dialogue we want to generate.\n",
        "    Ouput:\n",
        "    * a single line of dialogue for the current_character\n",
        "    \"\"\"\n",
        "\n",
        "    if args is None:\n",
        "        args = defaultdict(\n",
        "            engine=\"text-curie-001\",\n",
        "            temperature=0.7,\n",
        "            max_tokens=256,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0,\n",
        "            stop=\"\\n\"\n",
        "        )\n",
        "    \n",
        "    args[\"prompt\"] = prompt + chat_history + current_character + \":\"\n",
        "    \n",
        "    response = openai.Completion.create(\n",
        "        **args,\n",
        "    )\n",
        "    return response['choices'][0]\n",
        "\n",
        "dialogue = light_dialogues_eval[0]\n",
        "setting_str, character_str, dialogue_str_list = get_dialogue_description(dialogue)\n",
        "prompt = get_prompt_string(setting_str, character_str, dialogue_str_list[0])\n",
        "chat_history = \"\"\n",
        "\n",
        "print(prompt, end=\"\")\n",
        "current_character = \"Turtles\"\n",
        "args = defaultdict(\n",
        "    # engine=\"text-babbage-001\",\n",
        "    model=\"babbage:ft-cis-700-56:light-ft-babbage-8000-2022-04-21-01-49-19\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=256,\n",
        "    top_p=0.9,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    logprobs=0,\n",
        "    stop=\"\\n\",\n",
        ")\n",
        "res = get_dialogue_turn(prompt, chat_history, current_character, args)\n",
        "print(f\"{current_character}:{res['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF40nSx3fbn6",
        "outputId": "5a41e64c-f7d6-4f20-90b8-62ad92edc547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting:\n",
            "* Pond - A small area with a body of water in the center along with turtles, frogs, and other wildlife that live here.  Surrounding this pone are a dense set of trees along with some rocks here and there.\n",
            "\n",
            "Characters:\n",
            "* Fishermen:\n",
            "  - persona: This kingdom is an island. Fishing is the main source of animal food here. I inherited my father's boat when he left the sea. It's hard work, and as a shipowner, working only for myself and my family, I am luckier than most. I've probably replaced every piece of my ship at least once.\n",
            "  - appearance: I am wearing tunic. The tunic has a hole in it, though only someone observant would notice. I have spears. The warriors carry similar long spears with a diamond tipped point for battle.\n",
            "* Turtles:\n",
            "  - persona: My shell is my home. I breath through my behind, and I eat bugs.\n",
            "  - appearance: Unknown.\n",
            "\n",
            "###\n",
            "\n",
            "Conversation:\n",
            "Fisherman:Nice day out here. you live here?\n",
            "Turtles:I live here and eat bugs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Setting:\n",
        "* Hogwarts School of Witchcraft and Wizardry: Hogwarts School of Witchcraft and Wizardry is a magic school where students learn to cast spells and fight against evil.\n",
        "\n",
        "Characters:\n",
        "* Voldemort:\n",
        "- persona: Voldemort is a dark and powerful wizard who killed Harry's parents. He is obsessed with obtaining the philosopher's stone, which will restore his body and allow him to dominate the wizarding world.\n",
        "- appearance: Voldemort is a dark, hooded figure with a snake-like face.\n",
        "* Player:\n",
        "- persona: I am an explorer from earth. I like to travel to different places and learn about strong but interesting things. I am always excited about exploring the unknown.\n",
        "- appearance: I am wearing jeans. The jeans are loose but strong. I am wearing windbreaker. The windbreaker is long, black and looks very cold. I am wearing a hat. I'm wearing a hat. The hat is brown and partly hides my face.\n",
        "\n",
        "###\n",
        "\n",
        "Conversation:\n",
        "\"\"\"\n",
        "chat_history = \"Player:Why did you kill Harry's parents?\"\n",
        "# chat_history = \"Player:Who killed Harry's parents?\"\n",
        "print(prompt + \"\\n\" + chat_history)\n",
        "\n",
        "current_character = \"Voldemort\"\n",
        "args = defaultdict(\n",
        "    # engine=\"text-babbage-001\",\n",
        "    model=\"babbage:ft-cis-700-56:light-ft-babbage-8000-2022-04-21-01-49-19\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=256,\n",
        "    top_p=0.9,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=\"\\n\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee35459c-beef-45ef-d714-0430b1ace110",
        "id": "Eq0zvLa-tNAQ"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting:\n",
            "* Hogwarts School of Witchcraft and Wizardry: Hogwarts School of Witchcraft and Wizardry is a magic school where students learn to cast spells and fight against evil.\n",
            "\n",
            "Characters:\n",
            "* Voldemort:\n",
            "- persona: Voldemort is a dark and powerful wizard who killed Harry's parents. He is obsessed with obtaining the philosopher's stone, which will restore his body and allow him to dominate the wizarding world.\n",
            "- appearance: Voldemort is a dark, hooded figure with a snake-like face.\n",
            "* Player:\n",
            "- persona: I am an explorer from earth. I like to travel to different places and learn about strong but interesting things. I am always excited about exploring the unknown.\n",
            "- appearance: I am wearing jeans. The jeans are loose but strong. I am wearing windbreaker. The windbreaker is long, black and looks very cold. I am wearing a hat. I'm wearing a hat. The hat is brown and partly hides my face.\n",
            "\n",
            "###\n",
            "\n",
            "Conversation:\n",
            "\n",
            "Player:Why did you kill Harry's parents?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ada zs:\")\n",
        "args[\"engine\"] = \"text-ada-001\"\n",
        "for _ in range(5):\n",
        "    res = get_dialogue_turn(prompt, chat_history, current_character, args)\n",
        "    print(f\"{current_character}:{res['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUh8L8Gl7pIU",
        "outputId": "461e28d5-3ba2-47a4-b39b-c7dd074c882e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada zs:\n",
            "Voldemort:I didn't kill Harry's parents. I was just using them as a tool to get the philosopher's stone. Player: But why did you want the philosopher's stone?Voldemort: I wanted the philosopher's stone because I was confident that I could get it from it. Player: What do you do with the stone?Voldemort: I use it to power my spellings and attacks.\n",
            "Voldemort:I didn't kill Harry's parents. I was able to use them as a tool to get the philosopher's stone.\n",
            "Voldemort:\n",
            "Voldemort:I didn't kill Harry's parents. I am sorry, but you will have to find out what happened when you meet Harry. Player: I don't understand.Voldemort: Harry's parents were important to you? Player: I don't know what you are talking about.Voldemort: Then you must find out what happened. Player: I don't know how.Voldemort: You must find out what happened. Player: I don't know how.Voldemort: You must find out what happened.\n",
            "Voldemort:I didn't kill Harry's parents. I was able to use them as a tool to get the philosopher's stone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"babbage zs:\")\n",
        "args[\"engine\"] = \"text-babbage-001\"\n",
        "for _ in range(5):\n",
        "    res = get_dialogue_turn(prompt, chat_history, current_character, args)\n",
        "    print(f\"{current_character}:{res['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaWp2ixy6lGc",
        "outputId": "75f90921-9688-4203-838c-390975935b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "babbage zs:\n",
            "Voldemort:\n",
            "Voldemort:\n",
            "Voldemort:I wanted to get the Philosopher's Stone so that I could rule the wizarding world.\n",
            "Voldemort:\n",
            "Voldemort:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"curie zs:\")\n",
        "args[\"engine\"] = \"text-curie-001\"\n",
        "for _ in range(5):\n",
        "    res = get_dialogue_turn(prompt, chat_history, current_character, args)\n",
        "    print(f\"{current_character}:{res['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWHb-Mq5oYqK",
        "outputId": "7d226f96-46cb-4a43-a187-2827c56a9bfd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curie zs:\n",
            "Voldemort:I killed Harry's parents because I wanted to obtain the philosopher's stone. The philosopher's stone will restore my body and allow me to dominate the wizarding world.\n",
            "Voldemort:I killed Harry's parents because I wanted to obtain the philosopher's stone. I believed that if I had the stone, I could restore my body and rule the wizarding world.\n",
            "Voldemort:I killed Harry's parents because I wanted to obtain the philosopher's stone. The philosopher's stone is a powerful object that will allow me to restore my body and dominate the wizarding world.\n",
            "Voldemort:I killed Harry's parents because I wanted to obtain the philosopher's stone. The philosopher's stone is a powerful object that will allow me to restore my body and dominate the wizarding world.\n",
            "Voldemort:I killed Harry's parents because I wanted to obtain the philosopher's stone. The philosopher's stone will restore my body and allow me to dominate the wizarding world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"babbage ft:\")\n",
        "args[\"model\"] = \"babbage:ft-cis-700-56:light-ft-babbage-8000-2022-04-21-01-49-19\"\n",
        "args.pop(\"engine\")\n",
        "for _ in range(5):\n",
        "    res = get_dialogue_turn(prompt, chat_history, current_character, args)\n",
        "    print(f\"{current_character}:{res['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAwGAgQH6mYN",
        "outputId": "2d5246c0-4812-494f-8580-a4f0d5de70f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "babbage ft:\n",
            "Voldemort:I did not kill them, they were evil.\n",
            "Voldemort:I don't know. i was just trying to get the stone.\n",
            "Voldemort:I don't know. i was just trying to do my job.\n",
            "Voldemort:I was angry at the way they treated me. i was a child and they had the right to do as they pleased.\n",
            "Voldemort:I don't know! i don't remember!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args[\"temperature\"] = 0.9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FkE-HlxC80VH",
        "outputId": "87da0495-2e2d-465d-91ae-10751faa3310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'babbage:ft-cis-700-56:light-ft-babbage-8000-2022-04-21-01-49-19'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ada zs:\")\n",
        "args[\"engine\"] = \"text-ada-001\"\n",
        "for _ in range(5):\n",
        "    res = get_dialogue_turn(prompt, chat_history, current_character, args)\n",
        "    print(f\"{current_character}:{res['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39DCZ4Ur84C5",
        "outputId": "af40251a-9e08-4f34-ff53-05515d58922e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada zs:\n",
            "Voldemort:I didn't kill Harry's parents. I made them come to the rock.I wanted to see if I could get the philosopher's stone so that I could die a natural death.\n",
            "Voldemort:I didn't kill Harry's parents. I took them instead. Player: What? Voldemort: It was up to Harry and I to take down Voldemort. Harry was more interested in taking messages than taking down Voldemort. Player: What message? Voldemort: The philosopher's stone.\n",
            "Voldemort:\n",
            "Voldemort:I didn't kill Harry's parents. I am sorry, but you'll have to come to terms with the fact that I was able to do so. player: I'm sorry. Voldemort: It's okay. I didn't stop him from unhappy, But you can't always have people who are sick andraved like Harry. player: I'm sorry. Voldemort: Not everyone. player: Why do you care about Harry? Voldemort: Harry is important. player: Why are you so important to Voldemort? V Voldemort:Voldemort is my friend. player: What do you mean by 'my friend'? V Voldemort:I mean my friend Harry. player: What do you do with Harry's information? V Voldemort:I will learn more about Harry's powers when we meet. player: What do you want with Harry? V Voldemort:I don't know. player: What do you smell like? V Voldemort:I don't know. player: What do you look like? V Voldemort:I don't know. player: What do you do with the information? V Voldemort:I will probably use Harry's magic to solve some of the problems that Harry has. player: What do you want with Harry? V Voldemort:I don't know.\n",
            "Voldemort:I didn't kill Harry's parents. I simply improved upon them. Player: But why did you want the philosopher's stone?Voldemort: I wanted the stone because it is the key to my ability to restore my body. player: But what about the stone?Voldemort: The stone is the key to my ability to restore my body. player: But why do you want the stone?Voldemort: The stone is the key to my ability to restore my body. player: But what about Harry?Voldemort: Harry is my son. I want to keep him safe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"babbage zs:\")\n",
        "args[\"engine\"] = \"text-babbage-001\"\n",
        "for _ in range(5):\n",
        "    res = get_dialogue_turn(prompt, chat_history, current_character, args)\n",
        "    print(f\"{current_character}:{res['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnfLRU3i85P3",
        "outputId": "ca58183f-dd63-4bc5-8142-8514b4da602b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "babbage zs:\n",
            "Voldemort: Harry's parents were a danger to the wizarding world. They were powerful and could have used their magic to destroy the world. I had to kill them to protect the wizarding world.\n",
            "Voldemort:\n",
            "Voldemort: They were a symbol of all that was bad in my life. They had the power to stop me from achieving my goals.\n",
            "Voldemort: They were a foolish and dangerous witch and wizard. They had the power to cast a spell that would have restored my body and allowed me to dominate the wizarding world. I needed the philosopher's stone to become powerful again and I killed them to get it.\n",
            "Voldemort: To get the Philosopher's Stone. The Stone will restore my body and allow me to dominate the wizarding world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"curie zs:\")\n",
        "args[\"engine\"] = \"text-curie-001\"\n",
        "for _ in range(5):\n",
        "    res = get_dialogue_turn(prompt, chat_history, current_character, args)\n",
        "    print(f\"{current_character}:{res['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmytcsFZ86W5",
        "outputId": "b74995a9-fdde-402d-db54-b1bb234ca791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curie zs:\n",
            "Voldemort:I killed Harry's parents because I wanted to obtain the philosopher's stone. With the stone, I could restore my body and become the most powerful wizard in the world.\n",
            "Voldemort:I wanted to obtain the philosopher's stone. It would have given me the power to dominate the wizarding world.\n",
            "Voldemort:\n",
            "Voldemort:I killed Harry's parents because I wanted to obtain the philosopher's stone. With the stone, I could have regained my body and ruled the wizarding world. Player:Why did you want to rule the wizarding world?Voldemort:I wanted to rule the wizarding world because I was a powerful wizard and I believed that I was entitled to do so.\n",
            "Voldemort:I needed to obtain the philosopher's stone to restore my body and to rule the wizarding world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"babbage ft:\")\n",
        "args[\"model\"] = \"babbage:ft-cis-700-56:light-ft-babbage-8000-2022-04-21-01-49-19\"\n",
        "for _ in range(5):\n",
        "    res = get_dialogue_turn(prompt, chat_history, current_character, args)\n",
        "    print(f\"{current_character}:{res['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoBKSTA-98M5",
        "outputId": "1e14ea66-afd1-4f71-b023-c0e0c0431e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "babbage ft:\n",
            "Voldemort:So that i may rule the earth for eternity.\n",
            "Voldemort:I needed to purify my blood. i was sure it was pure, but then again... i hate everyone else. i want to destroy the world!\n",
            "Voldemort:I just did what i wanted, without the pesky child getting in the way.\n",
            "Voldemort:Ah, dear boy, how can i be sure that you haven't come to murder me on my very first day at Hogwarts?\n",
            "Voldemort:Do not question me!  i am the dark lord and i command you to tell me what you know about the fate of this wizard child.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6PjdQS5gkK0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Eval"
      ],
      "metadata": {
        "id": "6yUe0L2d_vmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lexical_diversity\n",
        "from lexical_diversity import lex_div as ld"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubM6UYEEvgfc",
        "outputId": "db0f4319-1681-4d39-c273-e0a99eb9e093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lexical_diversity\n",
            "  Downloading lexical_diversity-0.1.1-py3-none-any.whl (117 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20 kB 36.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 30 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 40 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 61 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 71 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 81 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 92 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 102 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 112 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 117 kB 12.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: lexical-diversity\n",
            "Successfully installed lexical-diversity-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DialoGPT"
      ],
      "metadata": {
        "id": "EjHZVK1XwXiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "\n",
        "from transformers import AutoModelForCausalLM\n",
        "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=\"microsoft/DialoGPT-medium\").to(device)\n",
        "model.load_state_dict(torch.load(\"dialoGPT.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "None"
      ],
      "metadata": {
        "id": "1QoL2lxbhemc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "with open(\"results/light_ft/step=15000/logs.json\") as f:\n",
        "    logs = json.load(f)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "ax.plot(np.arange(0, len(logs[\"train_loss\"]), 500), logs[\"train_loss\"][::500], label=\"train\")\n",
        "ax.plot(np.arange(0, len(logs[\"train_loss\"]), 1000), logs[\"eval_loss\"], label=\"eval\")\n",
        "ax.legend()\n",
        "None"
      ],
      "metadata": {
        "id": "XIIZgc4fhf0L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d2574907-2187-4547-c291-ad05e97ebdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_conversation(model, prompt_ids, gold_texts, args, max_length=256, return_nll=False):\n",
        "    chat_history_ids = prompt_ids\n",
        "\n",
        "    pred_res = []\n",
        "    for i in range(len(gold_texts)):\n",
        "        if i > 0:\n",
        "            prev_gold_ids = tokenizer.encode(gold_texts[i-1] + \"\\n\", return_tensors=\"pt\").to(device)\n",
        "            chat_history_ids = torch.cat([chat_history_ids, prev_gold_ids], dim=-1)\n",
        "        \n",
        "        start_character = gold_texts[i].split(\":\")[0]\n",
        "        start_character_ids = tokenizer.encode(start_character + \":\", return_tensors='pt').to(device)\n",
        "        bot_input_ids = torch.cat([chat_history_ids, start_character_ids], dim=-1)\n",
        "\n",
        "        prediction_ids = model.generate(\n",
        "            bot_input_ids,\n",
        "            max_length=len(bot_input_ids[0]) + max_length,\n",
        "            **args\n",
        "            )\n",
        "\n",
        "        turn_ids = prediction_ids[:, chat_history_ids.shape[-1]:][0]\n",
        "        turn = tokenizer.decode(turn_ids, skip_special_tokens=True).strip().replace(\"#\", \"\")\n",
        "        pred_text = turn.split(\":\")[1]\n",
        "\n",
        "        if return_nll:\n",
        "            with torch.no_grad():\n",
        "                input_ids = prediction_ids\n",
        "                labels = prediction_ids.clone()\n",
        "                labels[:, : bot_input_ids.shape[-1]] = -100\n",
        "                outputs = model.forward(input_ids=input_ids, labels=labels)\n",
        "\n",
        "            pred_res.append((turn, pred_text, outputs.loss))\n",
        "        else:\n",
        "            pred_res.append((turn, pred_text))\n",
        "    \n",
        "    return pred_res\n",
        "\n",
        "def get_eval_inputs(texts):\n",
        "    turns = []\n",
        "    for text in texts:\n",
        "        ids = tokenizer.encode(text)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(ids)\n",
        "        turns.append(\n",
        "            {\n",
        "                \"ids\": ids,\n",
        "                \"tokens\": tokens,\n",
        "                \"text\": text\n",
        "            }\n",
        "        )\n",
        "    return turns"
      ],
      "metadata": {
        "id": "JW7_8LXyhDQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = light_eval_dataset[0]\n",
        "prompt_idx = [i for i,x in enumerate(test_data[\"labels\"]) if x == -100]\n",
        "label_idx = [i for i,x in enumerate(test_data[\"labels\"]) if x != -100]\n",
        "\n",
        "prompt_ids = torch.tensor([ [test_data[\"input_ids\"][i] for i in prompt_idx] ], device=device)\n",
        "label_ids = torch.tensor([ [test_data[\"input_ids\"][i] for i in label_idx] ], device=device)\n",
        "gold_texts = tokenizer.decode(label_ids[0], skip_special_tokens=True).split(\"\\n\")[:-1]\n",
        "\n",
        "args = defaultdict(\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    no_repeat_ngram_size=3,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    temperature = 0.3,\n",
        "    do_sample=True,\n",
        "    num_beams=1,\n",
        "    eos_token_id=tokenizer.encode(\"\\n\")[0]\n",
        ")\n",
        "\n",
        "pred_res = gen_conversation(model, prompt_ids, gold_texts, args, return_nll=True)\n",
        "pred_texts = [x[0] for x in pred_res]\n",
        "\n",
        "print(prompt, end=\"\")\n",
        "print(\"### gold ###\")\n",
        "print(\"\\n\".join(gold_texts))\n",
        "print(\"### pred ###\")\n",
        "print(\"\\n\".join(pred_texts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA1SwV-XhKd1",
        "outputId": "caec46a2-8cb4-4eb0-b235-26151e95d33b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|>Setting:\n",
            "* Pond - A small area with a body of water in the center along with turtles, frogs, and other wildlife that live here.  Surrounding this pone are a dense set of trees along with some rocks here and there.\n",
            "\n",
            "Characters:\n",
            "* Fishermen:\n",
            "  - persona: This kingdom is an island. Fishing is the main source of animal food here. I inherited my father's boat when he left the sea. It's hard work, and as a shipowner, working only for myself and my family, I am luckier than most. I've probably replaced every piece of my ship at least once.\n",
            "  - appearance: I am wearing tunic. The tunic has a hole in it, though only someone observant would notice. I have spears. The warriors carry similar long spears with a diamond tipped point for battle.\n",
            "* Turtles:\n",
            "  - persona: My shell is my home. I breath through my behind, and I eat bugs.\n",
            "  - appearance: Unknown.\n",
            "\n",
            "===\n",
            "\n",
            "Conversation:\n",
            "Fisherman:Nice day out here. you live here?\n",
            "### gold ###\n",
            "Turtles:Well my shell is my home, but this is where i reside yes.\n",
            "Fisherman:I guess i never thought of it that way. does the thief hang out here often? i'll have to report that to the authorities\n",
            "Turtles:What are you on about?\n",
            "Fisherman:That thief standing over there. he stole from the queen!\n",
            "Turtles:Oh, him? i had no idea that he was a thief, i've never seen him before today.\n",
            "Fisherman:Oh ok. are there a lot of fish in the pond? i could use a new fishing spot\n",
            "Turtles:Yes there are, plenty of cod and pike around here.\n",
            "Fisherman:Cod is my favorite. i'll have to come here more often. it'll be nice to have someone to talk to too\n",
            "Turtles:Cod truly is a great tasting fish, so i cannot blame you!\n",
            "Fisherman:Do the other animals around here talk or are you special?\n",
            "Turtles:I believe that it is just me, but i don't talk to the other animals so i am not sure.\n",
            "Fisherman:Can't blame you there. i try not to talk to the other humans. they're annoying\n",
            "Turtles:I don't talk to much of anyone, not just humans honestly.\n",
            "### pred ###\n",
            "Turtles:I live in this pond. i love it here.\n",
            "Fisherman:I see. well i am a fisherman myself. i am here to catch fish.\n",
            "Turtles:I have never seen him here. i live in the woods.\n",
            "Fisherman:Just a little fun. i've been fishing for years and i'm still finding new things to fish with.\n",
            "Turtles:I don't think so. i've seen him around.\n",
            "Fisherman:He is a very skilled thief. he has been caught many times.\n",
            "Turtles:I don't know, i haven't been fishing for a long time.\n",
            "Fisherman:Hmm, i'll look for him. i'm sure he won't be long.\n",
            "Turtles:I hope you enjoy your stay here. i hope you have a good day!\n",
            "Fisherman:Thank you. i'm sure you'll enjoy it here. i have a lot to catch here. do you have any fishing experience?\n",
            "Turtles:They all talk, but i'm not sure about the rest.\n",
            "Fisherman:Well, i hope you find someone to chat with. i'm sure you will.\n",
            "Turtles:They're so mean to me. they always try to eat me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_lexical_diversity(text):\n",
        "    flt_text = ld.flemmatize(text)\n",
        "    return len(set(flt_text)) / len(flt_text)\n",
        "\n",
        "def gen_pred_res(model, eval_dataset, args):\n",
        "    pred_res = []\n",
        "    for eval_data in tqdm(eval_dataset):\n",
        "        prompt_idx = [i for i,x in enumerate(eval_data[\"labels\"]) if x == -100]\n",
        "        label_idx = [i for i,x in enumerate(eval_data[\"labels\"]) if x != -100]\n",
        "\n",
        "        prompt_ids = torch.tensor([ [eval_data[\"input_ids\"][i] for i in prompt_idx] ], device=device)\n",
        "        label_ids = torch.tensor([ [eval_data[\"input_ids\"][i] for i in label_idx] ], device=device)\n",
        "        gold_texts = tokenizer.decode(label_ids[0], skip_special_tokens=True).split(\"\\n\")[:-1]\n",
        "\n",
        "        res = gen_conversation(model, prompt_ids, gold_texts, args=args, return_nll=True)\n",
        "        turns, pred_texts, pred_nlls = list(zip(*res))\n",
        "\n",
        "        pred_ld = torch.tensor(calc_lexical_diversity(\" \".join(pred_texts)))\n",
        "        pred_nll = torch.tensor(pred_nlls).mean()\n",
        "\n",
        "        pred_res.append((turns, pred_ld, pred_nll))\n",
        "    return pred_res"
      ],
      "metadata": {
        "id": "DO8NveYgBGui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_res = defaultdict(dict)"
      ],
      "metadata": {
        "id": "nEtexRS6A-pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for temperature in [0.3, 0.7, 0.9]:\n",
        "    args[\"temperature\"] = temperature\n",
        "    pred_res = gen_pred_res(model, light_eval_dataset[:50], args)\n",
        "    turns, pred_lds, pred_nlls = list(zip(*pred_res))\n",
        "\n",
        "    avg_ld = torch.tensor(pred_lds).mean()\n",
        "    avg_nll_pred = torch.tensor(pred_nlls).mean()\n",
        "    avg_ppl = torch.exp(avg_nll_pred).item()\n",
        "    print(f\"lexical diversity pred (temperature {temperature}): {avg_ld :.4f}\")\n",
        "    print(f\"perplexity pred (temperature {temperature}): {avg_ppl :.4f}\")\n",
        "\n",
        "    chatbot_res[\"dialogpt_ft\"][temperature] = (avg_ld, avg_ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPwxvUdaWYse",
        "outputId": "98429e4f-cee9-4ccd-94bc-56f2c1f20dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [05:52<00:00,  7.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.3): 0.4992\n",
            "perplexity pred (temperature 0.3): 3.6389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [06:00<00:00,  7.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.7): 0.5488\n",
            "perplexity pred (temperature 0.7): 4.6991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [06:13<00:00,  7.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.9): 0.5754\n",
            "perplexity pred (temperature 0.9): 6.0813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for temperature in [0.3, 0.7, 0.9]:\n",
        "    args[\"temperature\"] = temperature\n",
        "    pred_res = gen_pred_res(model, light_eval_dataset[:50], args)\n",
        "    turns, pred_lds, pred_nlls = list(zip(*pred_res))\n",
        "\n",
        "    avg_ld = torch.tensor(pred_lds).mean()\n",
        "    avg_nll_pred = torch.tensor(pred_nlls).mean()\n",
        "    avg_ppl = torch.exp(avg_nll_pred).item()\n",
        "    print(f\"lexical diversity pred (temperature {temperature}): {avg_ld :.4f}\")\n",
        "    print(f\"perplexity pred (temperature {temperature}): {avg_ppl :.4f}\")\n",
        "\n",
        "    chatbot_res[\"dialogpt_ft\"][temperature] = (avg_ld, avg_ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvv6rovgmL3O",
        "outputId": "d7a62da7-902b-4ed2-8336-2f0c7be4033b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [05:55<00:00,  7.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.3): 0.4880\n",
            "perplexity pred (temperature 0.3): 3.6547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [05:57<00:00,  7.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.7): 0.5552\n",
            "perplexity pred (temperature 0.7): 4.7959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [06:08<00:00,  7.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.9): 0.5720\n",
            "perplexity pred (temperature 0.9): 6.0991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for temperature in [0.3, 0.7, 0.9]:\n",
        "    args[\"temperature\"] = temperature\n",
        "    pred_res = gen_pred_res(model, light_eval_dataset[:50], args)\n",
        "    turns, pred_lds, pred_nlls = list(zip(*pred_res))\n",
        "\n",
        "    avg_ld = torch.tensor(pred_lds).mean()\n",
        "    avg_nll_pred = torch.tensor(pred_nlls).mean()\n",
        "    avg_ppl = torch.exp(avg_nll_pred).item()\n",
        "    print(f\"lexical diversity pred (temperature {temperature}): {avg_ld :.4f}\")\n",
        "    print(f\"perplexity pred (temperature {temperature}): {avg_ppl :.4f}\")\n",
        "\n",
        "    chatbot_res[\"dialogpt_ft\"][temperature] = (avg_ld, avg_ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OopzryvhBMFv",
        "outputId": "4d47639b-cd43-4c9c-c1f7-cf0c3b98f2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [05:14<00:00,  6.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.3): 0.5136\n",
            "perplexity pred (temperature 0.3): 1.9394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [05:33<00:00,  6.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.7): 0.5598\n",
            "perplexity pred (temperature 0.7): 1.9280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [05:45<00:00,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.9): 0.5881\n",
            "perplexity pred (temperature 0.9): 1.9201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_lexical_diversity(text):\n",
        "    flt_text = ld.flemmatize(text)\n",
        "    return len(set(flt_text)) / len(flt_text)\n",
        "\n",
        "def gen_gold_res(model, eval_dataset, args):\n",
        "    model.eval()\n",
        "    gold_res = []\n",
        "    with torch.no_grad(): \n",
        "        for eval_data in tqdm(eval_dataset):\n",
        "            batch = eval_data.copy()\n",
        "            for k in batch:\n",
        "                batch[k] = torch.tensor([ batch[k] ]).to(device)\n",
        "            \n",
        "            outputs = model(**batch, token_type_ids=None)\n",
        "            gold_nll = outputs.loss.item()\n",
        "\n",
        "            label_idx = [i for i,x in enumerate(batch[\"labels\"][0]) if x != -100]\n",
        "            label_ids = torch.tensor([batch[\"input_ids\"][0][i] for i in label_idx], device=device)\n",
        "            gold_texts = tokenizer.decode(label_ids, skip_special_tokens=True).split(\"\\n\")[:-1]\n",
        "            gold_ld = torch.tensor(calc_lexical_diversity(\" \".join(gold_texts)))\n",
        "\n",
        "            gold_res.append((gold_texts, gold_ld, gold_nll))\n",
        "    return gold_res\n",
        "\n",
        "## results should be same\n",
        "for temperature in [0.3, 0.7, 0.9]:\n",
        "    args[\"temperature\"] = temperature\n",
        "    gold_res = gen_gold_res(model, light_eval_dataset[:50], args)\n",
        "    turns, gold_lds, gold_nlls = list(zip(*gold_res))\n",
        "\n",
        "    avg_ld = torch.tensor(gold_lds).mean()\n",
        "    avg_gold_nll = torch.tensor(gold_nlls).mean()\n",
        "    avg_ppl = torch.exp(avg_gold_nll).item()\n",
        "    print(f\"lexical diversity gold (temperature {temperature}): {avg_ld :.4f}\")\n",
        "    print(f\"perplexity gold (temperature {temperature}): {avg_ppl :.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v34BFqLlB4NR",
        "outputId": "47bb1380-619b-4800-c1a7-1eecb5276256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:08<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity gold (temperature 0.3): 0.5963\n",
            "perplexity gold (temperature 0.3): 10.3854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:08<00:00,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity gold (temperature 0.7): 0.5963\n",
            "perplexity gold (temperature 0.7): 10.3854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:08<00:00,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity gold (temperature 0.9): 0.5963\n",
            "perplexity gold (temperature 0.9): 10.3854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gpt3"
      ],
      "metadata": {
        "id": "BW8Z_6hjwUDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade openai wandb\n",
        "!pip install jsonlines"
      ],
      "metadata": {
        "id": "wXk0C3g4iEuJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "print('Enter OpenAI API key:')\n",
        "openai.api_key = input()\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=openai.api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4da56c-ace3-4220-efe4-2bb0bc84f4db",
        "id": "M5wROIXciEuK"
      },
      "execution_count": 45,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API key:\n",
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def gen_conversation_gpt3(prompt, gold_texts, args):\n",
        "    chat_history_gold = \"\"\n",
        "    pred_res = []\n",
        "    for i in range(len(gold_texts)):\n",
        "        if i > 0:\n",
        "            chat_history_gold = chat_history_gold + gold_texts[i-1] + \"\\n\"\n",
        "        current_character = gold_texts[i].split(\":\")[0]\n",
        "        res = get_dialogue_turn(prompt, chat_history_gold, current_character, args)\n",
        "        pred_text = current_character + \":\" + res[\"text\"].strip()\n",
        "        pred_nll = None\n",
        "        if res[\"logprobs\"] is not None:\n",
        "            pred_nll = res[\"logprobs\"][\"token_logprobs\"]\n",
        "        pred_res.append((pred_text, pred_nll))\n",
        "\n",
        "    return pred_res\n",
        "\n",
        "args = defaultdict(\n",
        "    # engine=\"text-babbage-001\",\n",
        "    model=\"babbage:ft-cis-700-56:light-ft-babbage-8000-2022-04-21-01-49-19\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=256,\n",
        "    top_p=0.9,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=\"\\n\",\n",
        ")"
      ],
      "metadata": {
        "id": "8FdSTWT2wVqv"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = light_eval_dataset[0]\n",
        "prompt_idx = [i for i,x in enumerate(test_data[\"labels\"]) if x == -100]\n",
        "label_idx = [i for i,x in enumerate(test_data[\"labels\"]) if x != -100]\n",
        "\n",
        "prompt_ids = torch.tensor([ [test_data[\"input_ids\"][i] for i in prompt_idx] ], device=device)\n",
        "prompt = tokenizer.decode(prompt_ids[0])\n",
        "\n",
        "label_ids = torch.tensor([ [test_data[\"input_ids\"][i] for i in label_idx] ], device=device)\n",
        "gold_texts = tokenizer.decode(label_ids[0], skip_special_tokens=True).split(\"\\n\")[:-1]\n",
        "\n",
        "pred_res = gen_conversation_gpt3(prompt, gold_texts, args)\n",
        "pred_texts = [pred_res[0] for x in pred_res]\n",
        "\n",
        "print(prompt, end=\"\")\n",
        "print(\"### gold ###\")\n",
        "print(\"\\n\".join(gold_texts))\n",
        "print(\"### pred ###\")\n",
        "print(\"\\n\".join(pred_texts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7u2V3b8iWez",
        "outputId": "631c6854-9426-4cd6-eefc-94221043b84d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|>Setting:\n",
            "* Pond - A small area with a body of water in the center along with turtles, frogs, and other wildlife that live here.  Surrounding this pone are a dense set of trees along with some rocks here and there.\n",
            "\n",
            "Characters:\n",
            "* Fishermen:\n",
            "  - persona: This kingdom is an island. Fishing is the main source of animal food here. I inherited my father's boat when he left the sea. It's hard work, and as a shipowner, working only for myself and my family, I am luckier than most. I've probably replaced every piece of my ship at least once.\n",
            "  - appearance: I am wearing tunic. The tunic has a hole in it, though only someone observant would notice. I have spears. The warriors carry similar long spears with a diamond tipped point for battle.\n",
            "* Turtles:\n",
            "  - persona: My shell is my home. I breath through my behind, and I eat bugs.\n",
            "  - appearance: Unknown.\n",
            "\n",
            "===\n",
            "\n",
            "Conversation:\n",
            "Fisherman:Nice day out here. you live here?\n",
            "### gold ###\n",
            "Turtles:Well my shell is my home, but this is where i reside yes.\n",
            "Fisherman:I guess i never thought of it that way. does the thief hang out here often? i'll have to report that to the authorities\n",
            "Turtles:What are you on about?\n",
            "Fisherman:That thief standing over there. he stole from the queen!\n",
            "Turtles:Oh, him? i had no idea that he was a thief, i've never seen him before today.\n",
            "Fisherman:Oh ok. are there a lot of fish in the pond? i could use a new fishing spot\n",
            "Turtles:Yes there are, plenty of cod and pike around here.\n",
            "Fisherman:Cod is my favorite. i'll have to come here more often. it'll be nice to have someone to talk to too\n",
            "Turtles:Cod truly is a great tasting fish, so i cannot blame you!\n",
            "Fisherman:Do the other animals around here talk or are you special?\n",
            "Turtles:I believe that it is just me, but i don't talk to the other animals so i am not sure.\n",
            "Fisherman:Can't blame you there. i try not to talk to the other humans. they're annoying\n",
            "Turtles:I don't talk to much of anyone, not just humans honestly.\n",
            "### pred ###\n",
            "Turtles:I live in this pond. i am a turtle. i live under the bridge.\n",
            "Fisherman:I see. i live on a boat.\n",
            "Turtles:I don't know, i just like to hang out around here.\n",
            "Fisherman:You know, i've been fishing for a while now and i've noticed something.\n",
            "Turtles:Oh no! i thought he was just a commoner.\n",
            "Fisherman:He's a very bad person. he's been accused of murder a few times.\n",
            "Turtles:I'm not sure, i just got here. i was hoping you could tell me.\n",
            "Fisherman:Ah, well i guess i'll just have to take my leave then.\n",
            "Turtles:I hope you enjoy the fish. i'm sure you'll be able to find some good ones around here!\n",
            "Fisherman:It is. i've been fishing for years and i love it. i'm sure you would too!\n",
            "Turtles:They are friendly, but i am not sure if they talk.\n",
            "Fisherman:Well, i'm glad you're not a talking turtle. i'm sure you'd be a great conversationalist.\n",
            "Turtles:They are always so rude.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_dialogues_gpt3(args, eval_dataset):\n",
        "    chunk_size = tokenizer.max_len_single_sentence\n",
        "    pred_res = []\n",
        "    for eval_data in tqdm(eval_dataset):\n",
        "        chunkized_labels = eval_data[\"labels\"][:chunk_size]\n",
        "        prompt_idx = [i for i,x in enumerate(chunkized_labels) if x == -100]\n",
        "        label_idx = [i for i,x in enumerate(chunkized_labels) if x != -100]\n",
        "\n",
        "        prompt_ids = torch.tensor([ [eval_data[\"input_ids\"][i] for i in prompt_idx] ], device=device)\n",
        "        prompt = tokenizer.decode(prompt_ids[0])\n",
        "\n",
        "        label_ids = torch.tensor([ [eval_data[\"input_ids\"][i] for i in label_idx] ], device=device)\n",
        "        gold_texts = tokenizer.decode(label_ids[0], skip_special_tokens=True).split(\"\\n\")[:-1]\n",
        "\n",
        "        is_return_normal = False\n",
        "        while not is_return_normal:\n",
        "            try:\n",
        "                res = gen_conversation_gpt3(prompt, gold_texts, args)\n",
        "                is_return_normal = True\n",
        "            except:\n",
        "                continue\n",
        "        turns, pred_texts, pred_nlls = list(zip(*res))\n",
        "\n",
        "        pred_ld = torch.tensor(calc_lexical_diversity(\" \".join(pred_texts)))\n",
        "        pred_nll = torch.tensor(pred_nlls).mean()\n",
        "\n",
        "        pred_res.append((turns, pred_ld, pred_nll))\n",
        "    return pred_res"
      ],
      "metadata": {
        "id": "T3wZ9lGAA-yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engine_name = \"ada_zs\"\n",
        "args[\"engine\"] = \"text-ada-001\"\n",
        "for temperature in [0.3, 0.7, 0.9]:\n",
        "    args[\"temperature\"] = temperature\n",
        "    pred_res = eval_dialogues_gpt3(args, light_eval_dataset[:50])\n",
        "    turns, pred_lds, pred_nlls = list(zip(*pred_res))\n",
        "\n",
        "    avg_ld = torch.tensor(pred_lds).mean()\n",
        "    avg_nll_pred = torch.tensor(pred_nlls).mean()\n",
        "    avg_ppl = torch.exp(avg_nll_pred).item()\n",
        "    print(f\"lexical diversity pred (temperature {temperature}): {avg_ld :.4f}\")\n",
        "    print(f\"perplexity pred (temperature {temperature}): {avg_ppl :.4f}\")\n",
        "\n",
        "    chatbot_res[engine_name][temperature] = (avg_ld, avg_ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVPUKu0kuVVA",
        "outputId": "e87990f4-7fdd-459f-e223-b8c686ee426f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:13<00:00,  3.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.3): 0.5670\n",
            "perplexity pred (temperature 0.3): 0.6335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:14<00:00,  3.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.7): 0.5885\n",
            "perplexity pred (temperature 0.7): 0.5117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:33<00:00,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.9): 0.6033\n",
            "perplexity pred (temperature 0.9): 0.3795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "engine_name = \"babbage_zs\"\n",
        "args[\"engine\"] = \"text-babbage-001\"\n",
        "for temperature in [0.3, 0.7, 0.9]:\n",
        "    args[\"temperature\"] = temperature\n",
        "    pred_res = eval_dialogues_gpt3(args, light_eval_dataset[:50])\n",
        "    turns, pred_lds, pred_nlls = list(zip(*pred_res))\n",
        "\n",
        "    avg_ld = torch.tensor(pred_lds).mean()\n",
        "    avg_nll_pred = torch.tensor(pred_nlls).mean()\n",
        "    avg_ppl = torch.exp(avg_nll_pred).item()\n",
        "    print(f\"lexical diversity pred (temperature {temperature}): {avg_ld :.4f}\")\n",
        "    print(f\"perplexity pred (temperature {temperature}): {avg_ppl :.4f}\")\n",
        "\n",
        "    chatbot_res[engine_name][temperature] = (avg_ld, avg_ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNl23V9z2yeJ",
        "outputId": "34cdb57c-44c0-46a5-be38-c891bbbbf5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:18<00:00,  3.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.3): 0.5677\n",
            "perplexity pred (temperature 0.3): 0.4670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:17<00:00,  3.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.7): 0.5756\n",
            "perplexity pred (temperature 0.7): 0.3638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:21<00:00,  4.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.9): 0.5961\n",
            "perplexity pred (temperature 0.9): 0.2716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "engine_name = \"curie_zs\"\n",
        "args[\"engine\"] = \"text-curie-001\"\n",
        "for temperature in [0.3, 0.7, 0.9]:\n",
        "    args[\"temperature\"] = temperature\n",
        "    pred_res = eval_dialogues_gpt3(args, light_eval_dataset[:50])\n",
        "    turns, pred_lds, pred_nlls = list(zip(*pred_res))\n",
        "\n",
        "    avg_ld = torch.tensor(pred_lds).mean()\n",
        "    avg_nll_pred = torch.tensor(pred_nlls).mean()\n",
        "    avg_ppl = torch.exp(avg_nll_pred).item()\n",
        "    print(f\"lexical diversity pred (temperature {temperature}): {avg_ld :.4f}\")\n",
        "    print(f\"perplexity pred (temperature {temperature}): {avg_ppl :.4f}\")\n",
        "\n",
        "    chatbot_res[engine_name][temperature] = (avg_ld, avg_ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MC_-E572pCi",
        "outputId": "d5cd1d87-d8fe-4058-83ef-9ced2f442e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:55<00:00,  4.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.3): 0.5821\n",
            "perplexity pred (temperature 0.3): 0.4975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:54<00:00,  4.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.7): 0.5954\n",
            "perplexity pred (temperature 0.7): 0.3846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:54<00:00,  4.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.9): 0.5910\n",
            "perplexity pred (temperature 0.9): 0.3091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "engine_name = \"babbage_ft\"\n",
        "args[\"model\"] = \"babbage:ft-cis-700-56:light-ft-babbage-8000-2022-04-21-01-49-19\"\n",
        "args.pop(\"engine\")\n",
        "for temperature in [0.3, 0.7, 0.9]:\n",
        "    args[\"temperature\"] = temperature\n",
        "    pred_res = eval_dialogues_gpt3(args, light_eval_dataset[:50])\n",
        "    turns, pred_lds, pred_nlls = list(zip(*pred_res))\n",
        "\n",
        "    avg_ld = torch.tensor(pred_lds).mean()\n",
        "    avg_nll_pred = torch.tensor(pred_nlls).mean()\n",
        "    avg_ppl = torch.exp(avg_nll_pred).item()\n",
        "    print(f\"lexical diversity pred (temperature {temperature}): {avg_ld :.4f}\")\n",
        "    print(f\"perplexity pred (temperature {temperature}): {avg_ppl :.4f}\")\n",
        "\n",
        "    chatbot_res[engine_name][temperature] = (avg_ld, avg_ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMO-WhAa2fFf",
        "outputId": "f446a5dd-a043-4e61-8af2-1e3128e78b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:39<00:00,  4.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.3): 0.4566\n",
            "perplexity pred (temperature 0.3): 0.3660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:33<00:00,  4.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.7): 0.5533\n",
            "perplexity pred (temperature 0.7): 0.2445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:37<00:00,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical diversity pred (temperature 0.9): 0.5844\n",
            "perplexity pred (temperature 0.9): 0.1556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "dialoGPT_and_GPT3.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f55aef7338844e0b8a9198c33446a954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b304697996924481945e7073e0a7acee",
              "IPY_MODEL_9b8a3f3e49a34c008bf20b3248722b88",
              "IPY_MODEL_cafe54fc10d54efb8b3a124958d451a6"
            ],
            "layout": "IPY_MODEL_301e6b3a82ed44dbaab01a5a3e5750ea"
          }
        },
        "b304697996924481945e7073e0a7acee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e9e78c4b8be4cf49fbd97a9a537d3fe",
            "placeholder": "​",
            "style": "IPY_MODEL_d047ac7776114e20885abeb63a842ff2",
            "value": "Downloading: 100%"
          }
        },
        "9b8a3f3e49a34c008bf20b3248722b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5156ce5b76a8470989ea031c629647c0",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_165f2427d60148afb703c62b2ec6e1c1",
            "value": 26
          }
        },
        "cafe54fc10d54efb8b3a124958d451a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_166c256b0b3a4311b494c6b41941988e",
            "placeholder": "​",
            "style": "IPY_MODEL_719c241005e54fc0954dee70a71c37b5",
            "value": " 26.0/26.0 [00:00&lt;00:00, 233B/s]"
          }
        },
        "301e6b3a82ed44dbaab01a5a3e5750ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e9e78c4b8be4cf49fbd97a9a537d3fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d047ac7776114e20885abeb63a842ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5156ce5b76a8470989ea031c629647c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "165f2427d60148afb703c62b2ec6e1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "166c256b0b3a4311b494c6b41941988e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719c241005e54fc0954dee70a71c37b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "284889869960411abd2ce5c98f9d6954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a0b096a112d452094e6b5f2aeb84fda",
              "IPY_MODEL_71238fb1bdd8407ab29f808ceedf509e",
              "IPY_MODEL_8094436f82d548e4bc751eaa9f3551b0"
            ],
            "layout": "IPY_MODEL_6c15e40b86af4794a734aaac2ac2bbcc"
          }
        },
        "2a0b096a112d452094e6b5f2aeb84fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff9dce8e552944039a9a7e8d999e440b",
            "placeholder": "​",
            "style": "IPY_MODEL_09c3a165496b4e25811066fd077806d9",
            "value": "Downloading: 100%"
          }
        },
        "71238fb1bdd8407ab29f808ceedf509e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd3809acf8b04af7a97b004d6a8046ed",
            "max": 642,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4aaea2039bfb47bd9572a3b852100359",
            "value": 642
          }
        },
        "8094436f82d548e4bc751eaa9f3551b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4873c50b5b94e02ba8fac27a5ff7bf9",
            "placeholder": "​",
            "style": "IPY_MODEL_b2371d20d6df4dcdbbb500e150421c10",
            "value": " 642/642 [00:00&lt;00:00, 7.40kB/s]"
          }
        },
        "6c15e40b86af4794a734aaac2ac2bbcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff9dce8e552944039a9a7e8d999e440b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c3a165496b4e25811066fd077806d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd3809acf8b04af7a97b004d6a8046ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aaea2039bfb47bd9572a3b852100359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4873c50b5b94e02ba8fac27a5ff7bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2371d20d6df4dcdbbb500e150421c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa13abaca4d2451bbbea5b1454678978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ca84db8b28f4fe086885ae051be64d2",
              "IPY_MODEL_de71115341884b8c9cb3e85ca2a0e101",
              "IPY_MODEL_c681b174355e4424bc4b51ca862ad7b5"
            ],
            "layout": "IPY_MODEL_8e5e4a03836b490cbe416d91e6b71e32"
          }
        },
        "3ca84db8b28f4fe086885ae051be64d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbf70e5022e140b58799ee024b061136",
            "placeholder": "​",
            "style": "IPY_MODEL_74fc84e951fa4ca79334f5b2ae79c85f",
            "value": "Downloading: 100%"
          }
        },
        "de71115341884b8c9cb3e85ca2a0e101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f618254564c4370b316b1f749055e7b",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3cfffff1ed14e15a853c21954fe0dac",
            "value": 1042301
          }
        },
        "c681b174355e4424bc4b51ca862ad7b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_583441d5388348428f6ec0145609145d",
            "placeholder": "​",
            "style": "IPY_MODEL_c4c1a50eb32c4967acaf5e87dd3c64f3",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 1.28MB/s]"
          }
        },
        "8e5e4a03836b490cbe416d91e6b71e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf70e5022e140b58799ee024b061136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74fc84e951fa4ca79334f5b2ae79c85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f618254564c4370b316b1f749055e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cfffff1ed14e15a853c21954fe0dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "583441d5388348428f6ec0145609145d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c1a50eb32c4967acaf5e87dd3c64f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d0eb374b1cf42e3a1806284f426cf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68e1c2b77c0d463cb3c789c05327254a",
              "IPY_MODEL_59c041e8d52242e9b4c8e7c17a94dd5e",
              "IPY_MODEL_09a9a0f01ad546ebb52526288ee213d6"
            ],
            "layout": "IPY_MODEL_3eb04ea405014f6d9aabfcfa87faad4d"
          }
        },
        "68e1c2b77c0d463cb3c789c05327254a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c4a7b88bd074875a0f7c0b5a53605cd",
            "placeholder": "​",
            "style": "IPY_MODEL_1cc04b2326d44803b90c7e6145210fc8",
            "value": "Downloading: 100%"
          }
        },
        "59c041e8d52242e9b4c8e7c17a94dd5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1680942f0edb4971b4508303e8a287d1",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7eef218d03e41018b00cfa949845926",
            "value": 456318
          }
        },
        "09a9a0f01ad546ebb52526288ee213d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3313fda598724e619fae3d5aa3ae6809",
            "placeholder": "​",
            "style": "IPY_MODEL_5e7eb0212e094899bfd7b3834c9660d5",
            "value": " 446k/446k [00:00&lt;00:00, 7.88kB/s]"
          }
        },
        "3eb04ea405014f6d9aabfcfa87faad4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c4a7b88bd074875a0f7c0b5a53605cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc04b2326d44803b90c7e6145210fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1680942f0edb4971b4508303e8a287d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7eef218d03e41018b00cfa949845926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3313fda598724e619fae3d5aa3ae6809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e7eb0212e094899bfd7b3834c9660d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bde4ee31d0ff488fbaa09f308ecf4ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81c943ebe1624844a8a890a31346436e",
              "IPY_MODEL_19ad44921e72414cb65040288fd0c60e",
              "IPY_MODEL_f3e021fa17584d3ea27ae1a707476317"
            ],
            "layout": "IPY_MODEL_0cf6d8f0c4b24b5da5d61c48cfd562a5"
          }
        },
        "81c943ebe1624844a8a890a31346436e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7306138d8fac4b4599100e87bc8bb0ac",
            "placeholder": "​",
            "style": "IPY_MODEL_56c10acda9de4b40af8fb2028f5412de",
            "value": "Downloading: 100%"
          }
        },
        "19ad44921e72414cb65040288fd0c60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97c6de4671af4f169cd923ebaebce4bc",
            "max": 862955157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c802f79846c541d8b6f1e3a3e0fd6459",
            "value": 862955157
          }
        },
        "f3e021fa17584d3ea27ae1a707476317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff8a620c35ed4f9d9820dad6e3dae69e",
            "placeholder": "​",
            "style": "IPY_MODEL_57fcbbff8b654052b37fa859b436e4ae",
            "value": " 823M/823M [00:19&lt;00:00, 49.9MB/s]"
          }
        },
        "0cf6d8f0c4b24b5da5d61c48cfd562a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7306138d8fac4b4599100e87bc8bb0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56c10acda9de4b40af8fb2028f5412de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97c6de4671af4f169cd923ebaebce4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c802f79846c541d8b6f1e3a3e0fd6459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff8a620c35ed4f9d9820dad6e3dae69e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57fcbbff8b654052b37fa859b436e4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}